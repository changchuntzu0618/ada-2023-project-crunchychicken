{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we want to do that? To get clean metadata.\n",
    "\n",
    "<div class='alert-warning'> Motivate the merge. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the CMU dataset with the IMDb dataset, we have to have a combination of common columns that uniquely identifies a movie on both datasets. \n",
    "\n",
    "The easiest is to merge them on the movie title.\n",
    "\n",
    "<div class='alert-warning'> Here we show why merging on the title is problematic. </div>\n",
    "\n",
    "The combination of the movie title and the year can be unique.\n",
    "\n",
    "<div class='alert-warning'> Here we show why this is also problematic. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling Wikipedia and querying Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movies in the CMU dataset are linked with the Wikipedia ID and the Freebase ID. In the IMDb dataset, they are identified by the IMDb IDs. If only there existed a mapping between Wikipedia ID / Freebase ID to IMDb IDs, the merging could be done. First, we check that these IDs can uniquely identify a movie:\n",
    "\n",
    "<div class='alert-warning'> ... </div>\n",
    "\n",
    "We notice that the same string also appears in the URL of the movie page on the IMDb website. With the help of an external library, [wikipedia](https://wikipedia.readthedocs.org/en/latest/), we can get the content of the Wikipedia page of a movie from its Wikipedia ID in the CMU dataset. We also notice that the IMDb page of the movie is most of the times referenced in the Wikipedia pages of the movies, meaning that we can link the two by crawling Wikipedia. However, this approach might fail if the IMDb page is not included anywhere in the Wikipedia page, or the Wikipedia page is not retrievable from its page ID.\n",
    "\n",
    "For these cases, we follow an alternative approach. In the Wikidata page of a movie, both the Freebase ID and the IMDb ID are listed. We can use the [Wikidata Query Service](https://query.wikidata.org) to match these two together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `helpers.crawl_wikipedia` and `helpers.crawl_wikidata` methods are used in `helpers.extract_cmu_imdb_mapping` to get such mappings. The whole process takes around 24 hours but can be improved by engineering the requests sent to Wikipedia by the external library. Since we only need to do this once, we opt to focus on the other parts and stick with the implementation of the external library. `helpers.extract_cmu_imdb_mapping` generates such mappings by the two methods, aggregates them, and stores the final mapping (and the most complete one) in `./generated/wp2imdb.csv`. The file is available in the repository but can be regenerated simply by running this function.\n",
    "\n",
    "We use this mapping in the rest of this section to merge the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import wikipedia\n",
    "from helpers import crawl_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the generated mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_01 = pd.read_csv('generated/wp2imdb_01.csv')\n",
    "mapping_02 = pd.read_csv('generated/wp2imdb_02.csv')\n",
    "mapping = pd.read_csv('generated/wp2imdb.csv')\n",
    "cmu_movies = pd.read_csv('data/MovieSummaries/movie.metadata.tsv', sep='\\t', usecols=[0, 1, 2], names=['wikipedia', 'freebase', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72180, 73894, 76885, 81741)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping_01), len(mapping_02), len(mapping.imdb.unique()), len(cmu_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 57 IMDb movies that are duplicated in the first method, and 11 in the second one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 11)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_01 = mapping_01[mapping_01.imdb.duplicated(keep=False)]\n",
    "duplicates_02 = mapping_02[mapping_02.imdb.duplicated(keep=False)]\n",
    "\n",
    "len(duplicates_01.imdb.unique()), len(duplicates_02.imdb.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the two mappings separately. First, we merge the duplicated mappings with the CMU table to get the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>imdb</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29912713</td>\n",
       "      <td>tt0011325</td>\n",
       "      <td>If I Were King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1364238</td>\n",
       "      <td>tt0011325</td>\n",
       "      <td>If I Were King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7971186</td>\n",
       "      <td>tt0021644</td>\n",
       "      <td>Laughing Gravy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7531222</td>\n",
       "      <td>tt0021644</td>\n",
       "      <td>Be Big!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>26192132</td>\n",
       "      <td>tt0025472</td>\n",
       "      <td>Marie Galante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>13734892</td>\n",
       "      <td>tt1535550</td>\n",
       "      <td>G.I. Joe: The Rise of Cobra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>36281191</td>\n",
       "      <td>tt1954470</td>\n",
       "      <td>Gangs of Wasseypur Part 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>31439778</td>\n",
       "      <td>tt1954470</td>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>27019957</td>\n",
       "      <td>tt2382698</td>\n",
       "      <td>Pulliman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>31156288</td>\n",
       "      <td>tt2382698</td>\n",
       "      <td>Pullimaan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     wikipedia       imdb                        title\n",
       "26    29912713  tt0011325               If I Were King\n",
       "101    1364238  tt0011325               If I Were King\n",
       "6      7971186  tt0021644               Laughing Gravy\n",
       "90     7531222  tt0021644                      Be Big!\n",
       "34    26192132  tt0025472                Marie Galante\n",
       "..         ...        ...                          ...\n",
       "84    13734892  tt1535550  G.I. Joe: The Rise of Cobra\n",
       "58    36281191  tt1954470    Gangs of Wasseypur Part 2\n",
       "47    31439778  tt1954470           Gangs of Wasseypur\n",
       "88    27019957  tt2382698                     Pulliman\n",
       "100   31156288  tt2382698                    Pullimaan\n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left=duplicates_01, right=cmu_movies.drop('freebase', axis=1), on='wikipedia', how='left').sort_values(by='imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the Wikipedia page ([17864265](https://en.wikipedia.org/wiki/Itsy_Bitsy_Spider_(film))) of the first movie, *Itsy Bitsy Spider*, we realize that although the found IMDb ID [tt0104536](https://www.imdb.com/title/tt0104536/) is right, the other Wikipedia ID ([1380383](https://en.wikipedia.org/wiki/Bebe%27s_Kids)) corresponds to a movie called *Babe's Kids*. The reason for finding the IMDb ID is that in this Wikipedia page, there is an external link to *Itsy Bitsy Spider* in the References section, which has made this confusion.\n",
    "\n",
    "We realize two things from this case:\n",
    "1. There could be such mistakes in the first method for matching Wikipedia ID with IMDb ID.\n",
    "2. It is more safe to stick with the second method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert-warning'> Is it the only possible situation?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://en.wikipedia.org/wiki/If_I_Were_King_(1920_film)',\n",
       " 'https://en.wikipedia.org/wiki/If_I_Were_King')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Check more cases (57 in total)\n",
    "\n",
    "wikipedia.page(pageid=29912713).url, wikipedia.page(pageid=1364238).url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing for the mapping from method 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freebase</th>\n",
       "      <th>imdb</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/m/0gwygmm</td>\n",
       "      <td>tt0003886</td>\n",
       "      <td>Enoch Arden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/m/04csqxh</td>\n",
       "      <td>tt0003886</td>\n",
       "      <td>Enoch Arden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/m/05zkmzh</td>\n",
       "      <td>tt0004047</td>\n",
       "      <td>Half Breed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/m/05zm_7t</td>\n",
       "      <td>tt0004047</td>\n",
       "      <td>The Conflicts of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/m/06zm9kt</td>\n",
       "      <td>tt0044592</td>\n",
       "      <td>Era lei che lo voleva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/m/06zp6s1</td>\n",
       "      <td>tt0044592</td>\n",
       "      <td>Oggi sposi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/m/0283_5p</td>\n",
       "      <td>tt0080422</td>\n",
       "      <td>Toothache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/m/0283_05</td>\n",
       "      <td>tt0080422</td>\n",
       "      <td>Dental Hygiene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/m/0gxvwy</td>\n",
       "      <td>tt0102359</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/m/0gxvw7</td>\n",
       "      <td>tt0102359</td>\n",
       "      <td>Light &amp; Heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/m/02qk_9g</td>\n",
       "      <td>tt0248428</td>\n",
       "      <td>Siva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/m/02gvt2</td>\n",
       "      <td>tt0248428</td>\n",
       "      <td>Shiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/m/0h68hf7</td>\n",
       "      <td>tt0268117</td>\n",
       "      <td>Anyay Abichar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/m/0gx1gwf</td>\n",
       "      <td>tt0268117</td>\n",
       "      <td>Aar Paar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/m/0gg5yw0</td>\n",
       "      <td>tt0319813</td>\n",
       "      <td>Ek Saudagar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/m/02qkzwc</td>\n",
       "      <td>tt0319813</td>\n",
       "      <td>Mannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/m/0h1c674</td>\n",
       "      <td>tt0358914</td>\n",
       "      <td>Maa avida Collector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/m/09rxk5h</td>\n",
       "      <td>tt0358914</td>\n",
       "      <td>Aavida Maa Aavide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/m/0d7_8l</td>\n",
       "      <td>tt0815890</td>\n",
       "      <td>Khan Kluay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/m/051z4n5</td>\n",
       "      <td>tt0815890</td>\n",
       "      <td>Jumbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/m/063_93d</td>\n",
       "      <td>tt1283913</td>\n",
       "      <td>High School Musical: El DesafÃ­o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/m/05znc1x</td>\n",
       "      <td>tt1283913</td>\n",
       "      <td>High School Musical: El Desafio Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      freebase       imdb                                   title\n",
       "17  /m/0gwygmm  tt0003886                             Enoch Arden\n",
       "14  /m/04csqxh  tt0003886                             Enoch Arden\n",
       "19  /m/05zkmzh  tt0004047                              Half Breed\n",
       "20  /m/05zm_7t  tt0004047                   The Conflicts of Life\n",
       "21  /m/06zm9kt  tt0044592                   Era lei che lo voleva\n",
       "12  /m/06zp6s1  tt0044592                              Oggi sposi\n",
       "3   /m/0283_5p  tt0080422                               Toothache\n",
       "7   /m/0283_05  tt0080422                          Dental Hygiene\n",
       "5    /m/0gxvwy  tt0102359                                Surprise\n",
       "18   /m/0gxvw7  tt0102359                           Light & Heavy\n",
       "2   /m/02qk_9g  tt0248428                                    Siva\n",
       "4    /m/02gvt2  tt0248428                                   Shiva\n",
       "15  /m/0h68hf7  tt0268117                           Anyay Abichar\n",
       "0   /m/0gx1gwf  tt0268117                                Aar Paar\n",
       "16  /m/0gg5yw0  tt0319813                             Ek Saudagar\n",
       "13  /m/02qkzwc  tt0319813                                  Mannan\n",
       "9   /m/0h1c674  tt0358914                     Maa avida Collector\n",
       "8   /m/09rxk5h  tt0358914                       Aavida Maa Aavide\n",
       "11   /m/0d7_8l  tt0815890                              Khan Kluay\n",
       "10  /m/051z4n5  tt0815890                                   Jumbo\n",
       "6   /m/063_93d  tt1283913         High School Musical: El DesafÃ­o\n",
       "1   /m/05znc1x  tt1283913  High School Musical: El Desafio Mexico"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left=duplicates_02, right=cmu_movies.drop('wikipedia', axis=1), on='freebase', how='left').sort_values(by='imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'freebase': '/m/04csqxh', 'imdb': 'tt0003886'},\n",
       " {'freebase': '/m/0gwygmm', 'imdb': 'tt0003886'},\n",
       " {'freebase': '/m/04csqxh', 'imdb': 'tt0001593'},\n",
       " {'freebase': '/m/04csqxh', 'imdb': 'tt0001594'}]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Check more cases (11 in total)\n",
    "crawl_wikidata(values=['/m/0gwygmm', '/m/04csqxh'], by='freebase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following query in [Wikidata Query Service](https://query.wikidata.org) to get the Wikidata pages and see what is happening:\n",
    "\n",
    "```SQL\n",
    "SELECT ?item ?attr ?imdbid WHERE {\n",
    "  ?item wdt:P345 ?imdbid .\n",
    "  ?item wdt:P646 ?attr\n",
    "  FILTER(?attr IN ('/m/0gwygmm', '/m/04csqxh'))\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\"> UPDATE THE CELLS BELOW </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should we do for the cases that we got the IMDb ID from the both methods? Which one should we merge on? It would not matter in principle but what if in these cases, we find a mismatch between the wikipedia-to-freebase mapping and the one that we have in the CMU dataset?\n",
    "\n",
    "Let's check that. We first merge the mapping with the movies dataframe on `wikipedia`. Then we look at the cases when `freebase` is different in the two columns of the merge. Ideally, they should always be the same, but as we will see, this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_01 = pd.merge(left=cmu_movies, right=mapping, on='freebase', how='left')\n",
    "mismatch = merge_01[~merge_01.wikipedia_y.isna() & (merge_01.wikipedia_x != merge_01.wikipedia_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_x</th>\n",
       "      <th>freebase</th>\n",
       "      <th>title</th>\n",
       "      <th>wikipedia_y</th>\n",
       "      <th>imdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>17864265</td>\n",
       "      <td>/m/047cn91</td>\n",
       "      <td>Itsy Bitsy Spider</td>\n",
       "      <td>1380383.0</td>\n",
       "      <td>tt0104536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>32136310</td>\n",
       "      <td>/m/0gx13n5</td>\n",
       "      <td>Tokyo Koen</td>\n",
       "      <td>30855569.0</td>\n",
       "      <td>tt1783792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>20903211</td>\n",
       "      <td>/m/05b13d8</td>\n",
       "      <td>Maya Machhindra</td>\n",
       "      <td>18849274.0</td>\n",
       "      <td>tt0242660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>28089857</td>\n",
       "      <td>/m/0cm83hd</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>28090138.0</td>\n",
       "      <td>tt0050552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>3963507</td>\n",
       "      <td>/m/025sxwm</td>\n",
       "      <td>The Year of the Quiet Sun</td>\n",
       "      <td>32755136.0</td>\n",
       "      <td>tt0088009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76844</th>\n",
       "      <td>22521800</td>\n",
       "      <td>/m/05zm_7t</td>\n",
       "      <td>The Conflicts of Life</td>\n",
       "      <td>22522087.0</td>\n",
       "      <td>tt0004047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77762</th>\n",
       "      <td>14748669</td>\n",
       "      <td>/m/03gwgp0</td>\n",
       "      <td>Ro.Go.Pa.G.</td>\n",
       "      <td>1952819.0</td>\n",
       "      <td>tt0056171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78610</th>\n",
       "      <td>22611251</td>\n",
       "      <td>/m/05zwphf</td>\n",
       "      <td>Deaf Sam-yong</td>\n",
       "      <td>4471177.0</td>\n",
       "      <td>tt0388760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79179</th>\n",
       "      <td>14712775</td>\n",
       "      <td>/m/03gt_yd</td>\n",
       "      <td>Follow the Boys</td>\n",
       "      <td>23951493.0</td>\n",
       "      <td>tt0057066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80158</th>\n",
       "      <td>173941</td>\n",
       "      <td>/m/017gl1</td>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>414113.0</td>\n",
       "      <td>tt0120737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wikipedia_x    freebase  \\\n",
       "2282      17864265  /m/047cn91   \n",
       "4982      32136310  /m/0gx13n5   \n",
       "5870      20903211  /m/05b13d8   \n",
       "6992      28089857  /m/0cm83hd   \n",
       "7117       3963507  /m/025sxwm   \n",
       "...            ...         ...   \n",
       "76844     22521800  /m/05zm_7t   \n",
       "77762     14748669  /m/03gwgp0   \n",
       "78610     22611251  /m/05zwphf   \n",
       "79179     14712775  /m/03gt_yd   \n",
       "80158       173941   /m/017gl1   \n",
       "\n",
       "                                                   title  wikipedia_y  \\\n",
       "2282                                   Itsy Bitsy Spider    1380383.0   \n",
       "4982                                          Tokyo Koen   30855569.0   \n",
       "5870                                     Maya Machhindra   18849274.0   \n",
       "6992                                            Istanbul   28090138.0   \n",
       "7117                           The Year of the Quiet Sun   32755136.0   \n",
       "...                                                  ...          ...   \n",
       "76844                              The Conflicts of Life   22522087.0   \n",
       "77762                                        Ro.Go.Pa.G.    1952819.0   \n",
       "78610                                      Deaf Sam-yong    4471177.0   \n",
       "79179                                    Follow the Boys   23951493.0   \n",
       "80158  The Lord of the Rings: The Fellowship of the Ring     414113.0   \n",
       "\n",
       "            imdb  \n",
       "2282   tt0104536  \n",
       "4982   tt1783792  \n",
       "5870   tt0242660  \n",
       "6992   tt0050552  \n",
       "7117   tt0088009  \n",
       "...          ...  \n",
       "76844  tt0004047  \n",
       "77762  tt0056171  \n",
       "78610  tt0388760  \n",
       "79179  tt0057066  \n",
       "80158  tt0120737  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the movie *Tokyo Koen*, we realize that the provided Wikipedia page in the CMU dataset (32136310) does not exist. The found IMDb [tt1783792](https://www.imdb.com/title/tt1783792/) belongs to a movie called *Tokyo Park*. However, when we check the Wikipedia page [30855569](https://en.wikipedia.org/wiki/Tokyo_Park) that is listed this URL, we can see that the movie has two titles: *Tokyo Koen* and *Tokyo Park*.\n",
    "\n",
    "From this case, we relize that some Wikipedia pages listed in the CMU dataset can be outdated or changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 99 movies with this situation. Let's zoom on a few of them to see what is happening. Having a different `wikipedia_y` means that, we found the same IMDb ID as the one that was found based on the Freebase ID, from a different Wikipedia page as listed in the CMU dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert-warning'> Actually, this makes the first method rubbish. I think we should try to improve that by checking the \"External Links\" section and run it again (for 15 hours), or to just stick with the second method, which limits us with only 73k movies instead of 76k. But let's include all of these analyses for P2.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Singapore_(1947_film)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.page(pageid=28090138).url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dummy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
