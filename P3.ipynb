{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b168f1",
   "metadata": {},
   "source": [
    "Just a first draft, delete, modify as you want \n",
    "\n",
    "**TODO**: add anchors for easy navigation, remove some dupplicated code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af16e2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from helpers.readers import prepare_dataframes, read_dataframe_parquet, read_dataframe\n",
    "from helpers.readers import save_parquet_to_generated, save_dict_to_generated, load_dict_from_generated\n",
    "from helpers.utils import PALETTE_D, PALETTE_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4825b8",
   "metadata": {},
   "source": [
    "# Q1:  How impactful is the team surrounding the director on the success of a movie?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13275bbe",
   "metadata": {},
   "source": [
    "To answer to this question, we need additional information than what we already have in the `movies` & `directors` dataframe. Namely, the `imdb_people` and `imdb_principals` dataframe are of interest here.\n",
    "\n",
    "- `imdb_people` contains birth/death years, primary professions and famous titles for ~12M people in the IMDb database\n",
    "\n",
    "- `imdb_principals` contains the principal (max 10 per movie) people that have played in movies in the IMDb database (roughs out to ~58M rows)\n",
    "\n",
    "\n",
    "They will thus be used to extract information about people that worked on the movies we selected. Their primary professions, the number of movies they played in, the potential nature of the roles they played in each movie (once actor, once writer, etc.)\n",
    "\n",
    "We first retrieve 'reduce' these two dataframes to only contain information about the movies we decided to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_crew = read_dataframe_parquet(\"imdb/crew\")\n",
    "imdb_info = read_dataframe_parquet(\"imdb/movies\")\n",
    "imdb_ratings = read_dataframe_parquet(name='imdb/ratings')\n",
    "\n",
    "movies = read_dataframe_parquet(\"cmu/movies\")\n",
    "movies = movies.drop(['Movie release Day', 'Movie release Month'], axis=1).copy()\n",
    "movies.rename(\n",
    "    columns={\n",
    "        'Wikipedia movie ID': 'wikipediaID',\n",
    "        'Freebase movie ID': 'freebaseID',\n",
    "        'Movie name': 'title',\n",
    "        'Movie box office revenue': 'revenue',\n",
    "        'Movie runtime': 'runtime',\n",
    "        'Movie languages': 'languages',\n",
    "        'Movie countries': 'countries',\n",
    "        'Movie genres': 'genres',\n",
    "        'Movie release Year': 'release',\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "mapping_w_i_f = read_dataframe(name='mapping_wikipedia_imdb_freebase')\n",
    "mapping_f_i = read_dataframe(name='mapping_freebase_imdb')\n",
    "\n",
    "\n",
    "movies = movies.merge(\n",
    "    right=mapping_f_i.drop_duplicates(subset='freebase'),\n",
    "    left_on='freebaseID', right_on='freebase', how='left'\n",
    ").rename(columns={'imdb': 'tconst'}).drop('freebase', axis=1)\n",
    "\n",
    "movies.tconst.duplicated().sum()\n",
    "movies.drop_duplicates(subset='tconst', inplace=True)\n",
    "\n",
    "movies = movies.merge(\n",
    "    right=imdb_info.rename(columns={'genres': 'genres_imdb', 'runtimeMinutes': 'runtime_imdb'})[['tconst', 'isAdult', 'runtime_imdb', 'genres_imdb']],\n",
    "    on='tconst', how='left',\n",
    ")\n",
    "\n",
    "movies = movies.merge(\n",
    "    right=imdb_ratings.rename(columns={'averageRating': 'rating', 'numVotes': 'votes'}),\n",
    "    on='tconst', how='left',\n",
    ")\n",
    "\n",
    "movies = movies.merge(right=imdb_crew.drop('writers', axis=1), on='tconst', how='left')\n",
    "\n",
    "# vectorized\n",
    "def compute_score(df):\n",
    "    df['score'] = np.log10(df['votes']) * df['rating']\n",
    "    return df\n",
    "\n",
    "movies = compute_score(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf74f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors = read_dataframe_parquet(\"q1/directors\")\n",
    "\n",
    "nmconsts = []\n",
    "for item in movies.dropna(subset='directors').directors.str.split(','):\n",
    "    nmconsts.extend(item)\n",
    "nmconsts = set(nmconsts)\n",
    "\n",
    "print(f'We have {len(nmconsts)} directors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50a084",
   "metadata": {},
   "source": [
    "### to unmarkdown?\n",
    "%%time\n",
    "imdb_info = read_dataframe_parquet(name='imdb/movies')\n",
    "imdb_ratings = read_dataframe_parquet(name='imdb/ratings')\n",
    "movieLens_movies = read_dataframe_parquet(name='movieLens/movies')\n",
    "movieLens_ratings = read_dataframe_parquet('movieLens/ratings')\n",
    "\n",
    "imdb_crew = read_dataframe_parquet(name='imdb/crew')\n",
    "imdb_people = read_dataframe_parquet(name='imdb/names')\n",
    "imdb_principals = read_dataframe_parquet(name='imdb/principals')\n",
    "\n",
    "#directors = imdb_people[imdb_people.nconst.isin(nmconsts)].copy()\n",
    "#directors = directors.set_index('nconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#```python\n",
    "def matching_selected_people(imdb_people,imdb_principals,movies) : \n",
    "\n",
    "    \"\"\"\n",
    "    This function filters the IMDb dataframes for people that worked on the selected movies.\n",
    "\n",
    "    Args :\n",
    "        imdb_people : The IMDb 'basic' dataframe. Contains information about people, f.i the movies they are known most for.\n",
    "        imdb_principals : The IMDb 'principals' dataframe. Contains information about the main cast of the IMDb movies, such as their name, job in the movie, role, etc.\n",
    "        movies : The dataset of selected movies\n",
    "\n",
    "    Returns :\n",
    "        matched_imdb_people : The IMDb 'basic' dataframe matched for our selected movies\n",
    "        jobs_principal_people : The IMDb 'principals' dataframe matched for our selected movies.\n",
    "    \"\"\"\n",
    "\n",
    "    #Exploding the imdb people dataframe to have all films played by people in the dataframe\n",
    "    imdb_people_exploded = imdb_people.copy()\n",
    "    imdb_people_exploded['knownForTitles'] = imdb_people['knownForTitles'].str.split(',')\n",
    "    imdb_people_exploded = imdb_people_exploded.explode(['knownForTitles'])\n",
    "\n",
    "    #Merging operations to retrieve the mapped information\n",
    "    merged_ipe = pd.merge(imdb_people_exploded,movies, how='inner', left_on='knownForTitles', right_on='tconst')\n",
    "    unique_matched_persons = merged_ipe.drop_duplicates(subset='nconst', keep='first')\n",
    "    matched_imdb_people = pd.merge(imdb_people, unique_matched_persons[['nconst']], on='nconst', how='inner')\n",
    "    tmp_principal_people = pd.merge(imdb_principals, matched_imdb_people[['nconst']], on='nconst', how='inner')\n",
    "    jobs_principal_people = pd.merge(tmp_principal_people,movies,on='tconst',how='inner')[['tconst','nconst','category','job']]\n",
    "\n",
    "    return(matched_imdb_people,jobs_principal_people)\n",
    "\n",
    "\n",
    "imdb_people = read_dataframe_parquet(name='imdb/names')\n",
    "imdb_principals = read_dataframe_parquet(name='imdb/principals')\n",
    "\n",
    "matched_imdb_people,jobs_principal_people = matching_selected_people(imdb_people,imdb_principals,movies)\n",
    "\n",
    "from helpers.readers import save_parquet_to_generated\n",
    "save_parquet_to_generated(\"q1_matched_imdb_people\",matched_imdb_people)\n",
    "save_parquet_to_generated(\"q1_jobs_principal_people\",jobs_principal_people)\n",
    "#```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b930857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut\n",
    "matched_imdb_people = read_dataframe_parquet(\"q1/matched_imdb_people\")\n",
    "jobs_principal_people = read_dataframe_parquet(\"q1/jobs_principal_people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#```python\n",
    "def get_all_known_roles(matched_principal,all_matched_people) : \n",
    "    \"\"\"\n",
    "    Adds additional movies that people present in the matched_principal dataframe passed as argument have played a certain role in.\n",
    "\n",
    "    Args:\n",
    "    matched_principal: The IMDb 'principal' dataframe matched for our selected movies. Contains\n",
    "                       information about the 'principal' crew of each movie.\n",
    "\n",
    "    all_matched_people: The IMDb 'people' dataframe matched for our selected movies. Contains\n",
    "                        personal information about people in the film industry.\n",
    "\n",
    "    Returns:\n",
    "    enhanced_matched_principal: The all_matched_people dataframe passed as argument, with an additional column\n",
    "                                containing any additional roles found in the matched_principal\n",
    "                                dataframe. \n",
    "    \"\"\"\n",
    "    roles_collected = {}\n",
    "\n",
    "    # Iterating over matched_principal to collect roles for each person\n",
    "    for _, row in tqdm(matched_principal.iterrows(),total=len(matched_principal),desc='Getting all known roles of our matched people'):\n",
    "        nconst = row['nconst']\n",
    "        tconst = row['tconst']\n",
    "        \n",
    "        if nconst not in roles_collected:\n",
    "            roles_collected[nconst] = set()\n",
    "\n",
    "        roles_collected[nconst].add(tconst)\n",
    "\n",
    "    # Updating enhanced_matched_principal with the collected roles\n",
    "    enhanced_matched_principal = all_matched_people.copy()\n",
    "    enhanced_matched_principal['all_known_roles'] = enhanced_matched_principal['nconst'].map(lambda x: ','.join(map(str, roles_collected.get(x,[]))))\n",
    "\n",
    "    return enhanced_matched_principal\n",
    "\n",
    "mip_enhanced = get_all_known_roles(jobs_principal_people,matched_imdb_people)\n",
    "save_parquet_to_generated(\"q1_mip_enhanced\",mip_enhanced)\n",
    "#```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut\n",
    "mip_enhanced = read_dataframe_parquet(\"q1/mip_enhanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#```python\n",
    "tqdm.pandas(desc='Adding the directed movies to each of our directors')\n",
    "\n",
    "def get_directed_movies(director_row, movies_df):\n",
    "    \"\"\"\n",
    "    Returns a list of the IMDb IDs of the movie directed by a certain director.\n",
    "\n",
    "    Args :\n",
    "        director_row : A row of the 'directors' dataframe, containing information about\n",
    "        movies_df : The dataframe containing the movies information\n",
    "    \"\"\"\n",
    "    curr_dir_id = director_row.name\n",
    "    directed_movies = ','.join(movies_df[movies_df.directors.str.contains(curr_dir_id)].index)\n",
    "    return directed_movies\n",
    "\n",
    "def add_directed_movies(directors_df, movies_df):\n",
    "    \"\"\"\n",
    "    Returns a modified version of the directors_df dataframe, with a new column indicating all the movies directed in the movies_df dataframe, for each director.\n",
    "\n",
    "    Args :\n",
    "        directors_df : The dataframe containing the director's information\n",
    "        movies_df : The dataframe containing the movies information\n",
    "\n",
    "    Returns :\n",
    "        directors_df : The original dataframe with the added column\n",
    "    \"\"\"\n",
    "    directors_df['directed_movies'] = directors_df.progress_apply(lambda row: get_directed_movies(row, movies_df), axis=1)\n",
    "    return directors_df\n",
    "\n",
    "enhanced_directors_df = add_directed_movies(directors, movies[['directors']])\n",
    "save_parquet_to_generated(\"q1_enhanced_directors\",enhanced_directors_df)\n",
    "#```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut\n",
    "enhanced_directors_df = read_dataframe_parquet(\"q1/enhanced_directors\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46062002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#```python\n",
    "def counting_directors_collaborations(directors_df, matched_imdb_people):\n",
    "    \"\"\"\n",
    "    Returns a dictionnary containing the number of collaborations between directors and different crew members, for the movies selected.\n",
    "\n",
    "    Args :\n",
    "    directors_df : A dataframe containing information about directors. it must contain at least the two following columns : 'nconst', the personal\n",
    "                   IMDb ID of the director, and 'directed_movies' which they have directed\n",
    "    \n",
    "                   \n",
    "    matched_imdb_people : A dataframe containing personal information about people that have worked on movies that we decided to retain. Must also contain\n",
    "                          the 'nconst' and 'knownForTitles' columns.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create a mapping of titles to people : For each title, we create a mapping which basically adds, for each movie, all the people we know have played some role in the movie\n",
    "    title_to_people = defaultdict(set)\n",
    "    for _, person_row in tqdm(matched_imdb_people.iterrows(),total=len(matched_imdb_people),desc='Mapping titles to people'):\n",
    "        person_id = person_row['nconst']\n",
    "        known_for_titles = person_row['knownForTitles']\n",
    "        all_known_roles = person_row['all_known_roles']\n",
    "\n",
    "        known_for_titles = known_for_titles.split(',') if isinstance(known_for_titles,str) else []\n",
    "        all_known_roles = all_known_roles.split(',') if isinstance(all_known_roles,str) else []\n",
    "\n",
    "        unique_movies = set(filter(None, known_for_titles + all_known_roles))\n",
    "        #print(person_id,unique_movies)\n",
    "        for title in unique_movies:\n",
    "                title_to_people[title].add(person_id)\n",
    "\n",
    "    collaboration_counts = {}\n",
    "    #Using the mapping, build the dictionnary of collaborations.\n",
    "    for _, row in tqdm(directors_df.iterrows(),total=len(directors_df), desc='Creating the dictionnary of collaborations'):\n",
    "        director_ids = set(row.name.split(',')) if isinstance(row.name, str) else set()\n",
    "        directed_titles = set(row['directed_movies'].split(',')) if isinstance(row['directed_movies'], str) else set()\n",
    "\n",
    "        for director_id in director_ids:\n",
    "            if director_id not in collaboration_counts:\n",
    "                collaboration_counts[director_id] = {}\n",
    "\n",
    "            for title in directed_titles:\n",
    "                collaborators = title_to_people[title] - {director_id}  # To remove the director from collaborators\n",
    "                for collaborator in collaborators:\n",
    "                    if collaborator not in collaboration_counts[director_id]:\n",
    "                        collaboration_counts[director_id][collaborator] = 1\n",
    "                    else:\n",
    "                        collaboration_counts[director_id][collaborator] += 1\n",
    "\n",
    "    return collaboration_counts\n",
    "\n",
    "collab_counts = counting_directors_collaborations(enhanced_directors_df,mip_enhanced)\n",
    "\n",
    "save_dict_to_generated(\"q1_collab_counts\", collab_counts)\n",
    "#```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_counts = load_dict_from_generated(\"q1_collab_counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61615f81",
   "metadata": {},
   "source": [
    "---\n",
    "### General overview of movie crews - How does the number of people working on the movies impact the success of the movies & directors ?\n",
    "\n",
    "Let's see how many different people each director has worked with, without looking at if they collaborated a lot with the same people at first :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_collaborators = []\n",
    "\n",
    "for director, collaborations in collab_counts.items():\n",
    "    num_collaborators = len(collaborations)\n",
    "    director_collaborators.append({'Director': director, 'NumCollaborators': num_collaborators})\n",
    "\n",
    "collab_counts_df = pd.DataFrame(director_collaborators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284008e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(collab_counts_df['NumCollaborators'], bins=range(1, max(collab_counts_df['NumCollaborators']) + 2), edgecolor='black',color=PALETTE_D[1])\n",
    "plt.xlabel('Number of Collaborators')\n",
    "plt.ylabel('Number of Directors')\n",
    "plt.title('Distribution of Collaborators per Director')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "hist, edges = np.histogram(collab_counts_df['NumCollaborators'], bins=range(1, max(collab_counts_df['NumCollaborators']) + 2))\n",
    "bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "plt.loglog(bin_centers, hist, 'o-', color=PALETTE_D[1], markeredgecolor='black', linewidth=2, markersize=4)\n",
    "plt.xlabel('Number of Collaborators (log$_{10}$ scale)')\n",
    "plt.ylabel('Number of Directors (log$_{10}$ scale)')\n",
    "plt.title('Log-log Distribution of Collaborators per Director', fontsize=16)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121cd067",
   "metadata": {},
   "source": [
    "We have a minority of directors that directed a huge number of films and thus had a huge number of collaborations throughout their career.\n",
    "Let's see if this behaviour reproduces for the size of the movie crew :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#```python\n",
    "def get_movie_crew_size(movies,matched_people) :\n",
    "    \"\"\" \n",
    "    Retrieves the movie crew size for selected movies.\n",
    "\n",
    "    Args : \n",
    "        movies : The dataframe containing information about our selected movies,\n",
    "        matched_people : The IMDb 'basics' dataframe mapped for the people in our selected movies only.\n",
    "\n",
    "    Returns :\n",
    "        final_movies : A copy of the 'movies' dataframe passed as argument with an additional column containing the crew size of the movie.\n",
    "    \"\"\"\n",
    "    #Retrieving all roles played by the individuals of the matched_people dataframe, taking the union on both to not count a movie twice\n",
    "    crew = matched_people.copy()\n",
    "    crew['knownForTitles'] = crew['knownForTitles'].apply(lambda x: set(x.split(',')) if isinstance(x, str) else set())\n",
    "    crew['all_known_roles'] = crew['all_known_roles'].apply(lambda x: set(x.split(',')) if isinstance(x, str) else set())\n",
    "    roles_union_df = crew[['knownForTitles', 'all_known_roles']].apply(lambda row: row['knownForTitles'].union(row['all_known_roles']), axis=1)\n",
    "\n",
    "    # Appropriate merges to return a modified version of the 'movies' dataframe\n",
    "    roles_union_df = pd.DataFrame({'nconst': crew['nconst'], 'roles_union': roles_union_df})\n",
    "    roles_union_df = roles_union_df.explode('roles_union')\n",
    "    merged_df = pd.merge(movies, roles_union_df, left_index=True, right_on='roles_union')\n",
    "    crew_sizes = pd.DataFrame(merged_df.groupby('roles_union')['nconst'].nunique())\n",
    "    crew_sizes.rename(columns={'nconst': 'crew_size'},inplace=True)\n",
    "    final_movies = pd.merge(movies,crew_sizes,left_index=True, right_index=True, how='left')\n",
    "\n",
    "    return final_movies\n",
    "\n",
    "movies_wcs = get_movie_crew_size(movies,mip_enhanced)\n",
    "save_parquet_to_generated(\"q1_movies_wcs\", movies_wcs)\n",
    "#```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d31000",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wcs = read_dataframe_parquet(\"q1/movies_wcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a014fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(movies_wcs['crew_size'], bins=range(1, int(max(movies_wcs['crew_size'])) + 2), edgecolor='black')\n",
    "plt.xlabel('Movie Crew size')\n",
    "plt.ylabel('Number of films')\n",
    "plt.title('Distribution of movie crew size')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "hist, edges = np.histogram(movies_wcs['crew_size'], bins=range(1, int(max(movies_wcs['crew_size'])) + 2))\n",
    "bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "plt.loglog(bin_centers, hist, 'o-', color=PALETTE_D[1], markeredgecolor='black', linewidth=2, markersize=4)\n",
    "plt.xlabel('Movie crew size (log$_{10}$ scale)')\n",
    "plt.ylabel('Number of movies (log$_{10}$ scale)')\n",
    "plt.title('Log-log Distribution of the movies\\' crew size', fontsize=16)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe1b06",
   "metadata": {},
   "source": [
    "How are our movie scores distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330afb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(movies['score'], bins=range(1, int(max(movies['score'])) + 2), color=PALETTE_D[1], edgecolor='black')\n",
    "plt.xlabel('Film score')\n",
    "plt.ylabel('Number of films')\n",
    "plt.title('Distribution of movie scores')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf4eae",
   "metadata": {},
   "source": [
    "Skewed, but not a power law. <br>\n",
    "Let us thus first see how the movie crew size is linked to the movie score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea980c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.regplot(x='crew_size', y='score', data=movies_wcs, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[0]})\n",
    "\n",
    "correlation_coefficient = movies_wcs['crew_size'].corr(movies_wcs['score'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color=PALETTE_D[4])\n",
    "plt.title('')\n",
    "plt.xlabel('Number of members working on the movie')\n",
    "plt.ylabel('Success score of the movie')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671ab84",
   "metadata": {},
   "source": [
    "A few number of outliers with huge movie crewsizes : let's remove them to keep some reasonable crew sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ccac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_wscs = movies_wcs[movies_wcs['crew_size'] < 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e05c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.regplot(x='crew_size', y='score', data=movies_wscs, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[0]})\n",
    "\n",
    "correlation_coefficient = movies_wscs['crew_size'].corr(movies_wscs['score'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color=PALETTE_D[4])\n",
    "plt.title('')\n",
    "plt.xlabel('Number of members working on the movie')\n",
    "plt.ylabel('Success score of the movie')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189fe19",
   "metadata": {},
   "source": [
    "Difficult to assess the meaningfulness of the correlation between the size of the movie crew and the score of the movie. Let's display our first 10 movies in terms of score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_movies = movies_wscs.sort_values(by='score', ascending=False).head(15)\n",
    "top_10_movies = top_10_movies.sort_values(by='score', ascending=True)\n",
    "\n",
    "top_10_movies = top_10_movies.head(15)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Barplot 1: Crew Size\n",
    "ax1.barh(top_10_movies['title'], top_10_movies['crew_size'], color= PALETTE_D[0])\n",
    "ax1.set_xlabel('Crew Size')\n",
    "ax1.set_title('Crew Size of Top 10 Movies')\n",
    "\n",
    "# Barplot 2: Score\n",
    "ax2.barh(top_10_movies['title'], top_10_movies['score'], color=PALETTE_D[1])\n",
    "ax2.set_xlabel('Score')\n",
    "ax2.set_title('Score of Top 10 Movies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa905f",
   "metadata": {},
   "source": [
    "We can just see that even amongst our most popular movies, we have the LOTR films & inception with a huge number of people who are credited, but actually the Godfather has a rather small crew size when compared to the latter. <br>\n",
    "If the impact on a certain movie is thus not really established, Let's try to see how the directors surround themselves for their movies : do they always have a huge number of people around them ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f0b8b",
   "metadata": {},
   "source": [
    "### bug zone start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_directors_df['directed_movies'] = enhanced_directors_df['directed_movies'].apply(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e97a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oui = enhanced_directors_df.copy(deep=True)\n",
    "\n",
    "oui['directed_movies'] = oui['directed_movies'].apply(lambda x: str(x).split(','))\n",
    "\n",
    "# Explode the lists to separate rows for each movie ID\n",
    "directors_exploded = oui.explode('directed_movies')\n",
    "\n",
    "merged_df = pd.merge(directors_exploded, movies_wcs, how='left', left_on='directed_movies', right_index=True)\n",
    "\n",
    "# Filter for rows where the director has directed at least 3 movies\n",
    "filtered_directors = merged_df.groupby('nconst').filter(lambda x: x['directed_movies'].nunique() >= 3)\n",
    "\n",
    "# Calculate the average crew size for each director\n",
    "average_crew_size = pd.DataFrame(filtered_directors.groupby('nconst')['crew_size'].mean())\n",
    "\n",
    "average_crew_size.rename(columns={'crew_size' : 'avg_crew_size'},inplace=True)\n",
    "\n",
    "enhanced_directors_df = pd.merge(enhanced_directors_df,average_crew_size,how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = enhanced_directors_df.dropna(subset=['avg_crew_size', 'avg-3'])\n",
    "tmp_df[['avg_crew_size', 'avg-3']] = tmp_df[['avg_crew_size', 'avg-3']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.regplot(x='avg_crew_size', y='avg-3', data=tmp_df, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[0]})\n",
    "\n",
    "correlation_coefficient = tmp_df['avg_crew_size'].corr(tmp_df['avg-3'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color='red')\n",
    "plt.title('-')\n",
    "plt.xlabel('Average crew size per director')\n",
    "plt.ylabel('avg-3 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01eacd6",
   "metadata": {},
   "source": [
    "Interesting behaviour : seems like for averages inferior to a certain size there is a correlation between avg-3 score of the director and his/her average crew size but this is unbalanced when taking the movies superior to a certain size. Let's separate the directors in two to see how the two 'director' populations behave :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b147e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_crew_directors = tmp_df[tmp_df['avg_crew_size'] >= 300]\n",
    "small_crew_directors = tmp_df[tmp_df['avg_crew_size'] < 300]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# For small crew dirs\n",
    "ax = sns.regplot(x='avg_crew_size', y='avg-3', data=small_crew_directors, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[0]}, ax=axes[0])\n",
    "correlation_coefficient = small_crew_directors['avg_crew_size'].corr(small_crew_directors['avg-3'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color=PALETTE_D[2])\n",
    "axes[0].set_title('Directors with Fewer than 300 Crew Members on average')\n",
    "\n",
    "# For large crew dirs\n",
    "ax = sns.regplot(x='avg_crew_size', y='avg-3', data=large_crew_directors, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[4]}, ax=axes[1])\n",
    "correlation_coefficient = large_crew_directors['avg_crew_size'].corr(large_crew_directors['avg-3'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color='red')\n",
    "axes[1].set_title('Directors with 300 or More Crew Members on average')\n",
    "\n",
    "\n",
    "fig.suptitle('Scatter Plot of Average Crew Size vs. avg-3 Score for Directors')\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Average Crew Size')\n",
    "    ax.set_ylabel('avg-3 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c0db5",
   "metadata": {},
   "source": [
    "To see where the 'shift' happens, let's try and plot the evolution of the correlation coefficient of the avg-3 score with the size of the movie crew :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb91877",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dict = {}\n",
    "\n",
    "threshold_values = range(0, 3000, 1)\n",
    "max_correlation_coefficient = 0\n",
    "optimal_threshold = 0\n",
    "\n",
    "#iterating over the threshold values to get the correlation coefficients, each time\n",
    "for threshold in threshold_values:\n",
    "    \n",
    "    selected_directors = tmp_df[tmp_df['avg_crew_size'] <= threshold]\n",
    "\n",
    "    correlation_coefficient = selected_directors['avg_crew_size'].corr(selected_directors['avg-3'])\n",
    "\n",
    "\n",
    "    correlation_dict[threshold] = correlation_coefficient\n",
    "\n",
    "    if correlation_coefficient > max_correlation_coefficient:\n",
    "        max_correlation_coefficient = correlation_coefficient\n",
    "        optimal_threshold = threshold\n",
    "\n",
    "# Extract the lists of thresholds and correlation coefficients\n",
    "thresholds = list(correlation_dict.keys())\n",
    "correlation_coefficients = list(correlation_dict.values())\n",
    "\n",
    "plt.plot(thresholds, correlation_coefficients, marker='o', markersize=0.05,color=PALETTE_D[1], label='Correlation Coefficient')\n",
    "plt.scatter(optimal_threshold, max_correlation_coefficient, color=PALETTE_D[4], s=10, label=f'Max Correlation\\nThreshold={optimal_threshold}')\n",
    "plt.xlabel('Maximum value of the average crew size considered')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.title('Correlation Coefficient vs Threshold for avg_crew_size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal Threshold: {optimal_threshold}')\n",
    "print(f'Max Correlation Coefficient: {max_correlation_coefficient}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8083ee",
   "metadata": {},
   "source": [
    "Starting from a crew size of approximately 400, there starts to be a decrease in correlation between the average crew size of the director and its success. Could mean that too many members on seevral movie crews for a director can be detrimental to the success of directors.\n",
    "\n",
    "That's an interesting conclusion : the crew size of the movie does not necessarily matter for a specific movie : very successful movies have both had crew sizes that are inferior to the 'threshold' we just found and very well above while still being successful. However, it seems that for directors that always work with a huge crew, the director's success gets impacted.\n",
    "\n",
    "Nolan for instance indeed had a crew of 1200+ people on inception, but looking at his other films :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f7f2c",
   "metadata": {},
   "source": [
    "### bug zone end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df28744",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nolan_movies = movies_wscs[movies_wscs['directors'].str.contains('nm0634240')].sort_values(by='score', ascending=False).head(10)\n",
    "top_nolan_movies = top_nolan_movies.sort_values(by='score', ascending=True)\n",
    "\n",
    "top_nolan_movies = top_nolan_movies.head(10)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Barplot 1: Crew Size\n",
    "ax1.barh(top_nolan_movies['title'], top_nolan_movies['crew_size'], color=PALETTE_D[0])\n",
    "ax1.set_xlabel('Crew Size')\n",
    "ax1.set_title('Crew Size of Top 10 Movies')\n",
    "\n",
    "# Barplot 2: Score\n",
    "ax2.barh(top_nolan_movies['title'], top_nolan_movies['score'], color=PALETTE_D[1])\n",
    "ax2.set_xlabel('Score')\n",
    "ax2.set_title('Score of Top 10 Movies')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e03ca5",
   "metadata": {},
   "source": [
    "It's not something that necessarily repeats. Even among some of his most prestigious films, the crew size is not larger than 400 people, which is approximately the average crew size theshold we saw earlier where there really starts to be a decrease in correlation between director's success and avg crew size.\n",
    "\n",
    "\n",
    "**--> Does the crew size has an impact on the success of a movie ?** : In absolute, no. There is of course going to be very few movies with extremely limited crew sizes that are as famous as the hollywood ones, but that's probably just cofounded by the budget of the movie or other elements that effect how this crew can be built.\n",
    "\n",
    "**--> Does the crew size of the different movies of a director have an impact on its success ?** There is a clear relationship between a director's success and its crew sizes, that's worsening as much as the average crew size of a director evolves. It's for sure not the only factor impacting, but it does not play in favour of the directors.\n",
    "\n",
    "Nuance : We still have a very vew numbers of directors with relatively big (>300) movie crews on average, because as we saw both the number of collaborations & movie crew sizes follow rather closely a power law, which makes sense, so it's also a matter of distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9132956",
   "metadata": {},
   "source": [
    "---\n",
    "## Are the directors who always work with the same crew more successful?\n",
    "\n",
    "Now, let's try to see what's the behaviour of the number of collaborations of each director's. How many directors tend to work with similar people across their directed movies ? \n",
    "\n",
    "Quick function that retrieves all the persons that starred in some movies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_crew(movies,matched_people) :\n",
    "    \n",
    "\n",
    "    #The beginning of the function is really similar to get_movie_crew_size, but the rest of the operation differ as it performs a matching to retrieve the crew of each specific\n",
    "    #movie\n",
    "    crew = matched_people.copy()\n",
    "    tqdm.pandas(desc=\"knownForTitles under str form\")\n",
    "    crew['knownForTitles'] = crew['knownForTitles'].progress_apply(lambda x: set(x.split(',')) if isinstance(x, str) else set())\n",
    "    tqdm.pandas(desc=\"all_known_roles under str form\")\n",
    "    crew['all_known_roles'] = crew['all_known_roles'].progress_apply(lambda x: set(x.split(',')) if isinstance(x, str) else set())\n",
    "\n",
    "    tqdm.pandas(desc=\"Taking union of knownForTitles & all_known_roles\")\n",
    "    roles_df = crew[['knownForTitles', 'all_known_roles']].progress_apply(lambda row: row['knownForTitles'].union(row['all_known_roles']), axis=1)\n",
    "    roles_df = pd.DataFrame({'nconst': crew['nconst'], 'roles_union': roles_df})\n",
    "    #roles_df = roles_df.explode('roles_union')\n",
    "\n",
    "    tt_nconst_mapping = {}\n",
    "    selected_movies = set(movies.index)\n",
    "    #Itering through each row and update the dictionary created just above\n",
    "    rows = []\n",
    "    for index, row in tqdm(roles_df.iterrows(), total=len(roles_df), desc=\"Finding crew members\", leave=False):\n",
    "        nconst_id = row['nconst']\n",
    "        tt_ids = row['roles_union']\n",
    "\n",
    "        for tt_id in tt_ids:\n",
    "            if tt_id in selected_movies:\n",
    "                rows.append({'nconst': nconst_id, 'roles_union': tt_id})\n",
    "\n",
    "    roles_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Group by 'roles_union' and aggregate 'nconst' as a list\n",
    "    tt_nconst_mapping = roles_df.groupby('roles_union')['nconst'].agg(list).to_dict()\n",
    "\n",
    "    return tt_nconst_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_crews = get_movie_crew(movies_wcs,mip_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parquet_to_generated(\"q1_movie_crews\", movie_crews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb72821",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_crews = read_dataframe_parquet(\"q1/movie_crews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79979362",
   "metadata": {},
   "source": [
    "What we do here is we want to measure how directors change their crew overtime. We thus use the Overlap coefficient to measure the changes : It's the intersection of the crews divided by the size of the minimum of the two crews. We take the minimum here because we don't want to penalize the computations if the crew sizes are too different, what interests us here is just to know, overall, how much the directors keep people from one movie to the other. If all the people from movie 1 are moved to movie 2, even if movie 2 has more people, will yield a coefficient of 1, which is good because we want to maximize these kind of events as we do not have extensive information about the entire crews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_coefficient(set1, set2):\n",
    "    intersection_size = len(set1.intersection(set2))\n",
    "    min_size = max(len(set1), len(set2))\n",
    "    return intersection_size / min_size if min_size > 0 else 0\n",
    "\n",
    "\n",
    "enhanced_directors_df = enhanced_directors_df.dropna(subset=['avg_crew_size', 'avg-3'])\n",
    "directors_copy = enhanced_directors_df.copy(deep=True)\n",
    "directors_copy['avg_crew_change'] = 0.0 \n",
    "\n",
    "\n",
    "for index, row in tqdm(directors_copy.iterrows(), total=len(directors_copy), desc=\"Finding crew similarities for the directors\", leave=False) :\n",
    "    director_id = index\n",
    "    directed_movies = row['directed_movies'].split(',')\n",
    "\n",
    "    # Get the set of crew members for each movie directed by the director\n",
    "    director_crews = [set(movie_crews[movie_id]) for movie_id in directed_movies if movie_id in movie_crews]\n",
    "\n",
    "    # Calculate crew changes\n",
    "    crew_changes = []\n",
    "    for i in range(len(director_crews) - 1):\n",
    "        for j in range(i + 1, len(director_crews)):\n",
    "            overlap_coeff = overlap_coefficient(director_crews[i], director_crews[j])\n",
    "            crew_changes.append(overlap_coeff)\n",
    "\n",
    "    # Calculate the average crew change for the director\n",
    "    avg_crew_change = sum(crew_changes) / len(crew_changes) if crew_changes else 0\n",
    "    directors_copy.at[index, 'avg_crew_change'] = avg_crew_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1983f536",
   "metadata": {},
   "source": [
    "We must however be careful that the measure biased because of the fact that we lack information for some directors. Maybe they had more than 7 people in their crew on average, but IMDb does not provide the rightful information about it.\n",
    "\n",
    "Let's try, therefore, to only consider the ones with a sufficient crew size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_copy = directors_copy.dropna(subset=['avg_crew_change', 'avg-3']).copy()\n",
    "directors_copy[['avg_crew_change', 'avg-3']] = directors_copy[['avg_crew_change', 'avg-3']].apply(pd.to_numeric, errors='coerce')\n",
    "directors_copy = directors_copy[directors_copy['avg_crew_size'] > 20]\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.regplot(x='avg_crew_change', y='avg-3', data=directors_copy, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[4]})\n",
    "\n",
    "correlation_coefficient = directors_copy['avg_crew_change'].corr(directors_copy['avg-3'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color='red')\n",
    "plt.title('-')\n",
    "plt.xlabel('Average crew similarity (Overlap Coefficient)')\n",
    "plt.ylabel('avg-3 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ac8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_copy = directors_copy.dropna(subset=['avg_crew_change', 'avg-3']).copy()\n",
    "\n",
    "# Convert columns to numeric (if not already numeric)\n",
    "directors_copy[['avg_crew_change', 'avg-3']] = directors_copy[['avg_crew_change', 'avg-3']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot distribution of 'avg-3' score with respect to average crew similarity\n",
    "ax = sns.histplot(y='avg-3', x='avg_crew_change', data=directors_copy, bins=100, cmap=PALETTE_C, cbar=True, fill=True)\n",
    "\n",
    "plt.title('Distribution of avg-3 Score with respect to Average Crew Similarity')\n",
    "plt.ylabel('avg-3 Score')\n",
    "plt.xlabel('Average Crew Similarity (Overlap Coefficient)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b2678",
   "metadata": {},
   "source": [
    "If we consider the entire crews, it seems that the majority of directors tend to change crews between movies. The majority of directors have average scores in the 15-30 range with overlap coefficients from 0 to 0.05, hence seemingly changing crews in between films.\n",
    "\n",
    "Moreover, the most successful directors also have rather low overlap coefficients. From this alone, it seems like directors, whatever their success is, tend do change crews in between movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_copy.sort_values(by='avg_crew_change',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297fdc5",
   "metadata": {},
   "source": [
    "Most likely, yes. It's easier to get an overlap coefficient that is big if you have a very small number of collaborations on each film and you always work with nearly the same one(s). What this overlap coefficient rather indicates is that directors with large crews will unevitabely suffer changes from one film to the other, but we can not really assess the impact of these changes on director's success with this overlap coefficient alone. \n",
    "\n",
    "**Are the directors who always work with the same crew more successful?** --> If we take the entirety of the crew, then it does not seem that directors that keep their entire crew are most successful, graphs even tend to show the opposite. However, due to the lack of solid IMDb data with respect to the exact entire crews, it may be scuffed.\n",
    "\n",
    "------\n",
    "## Is directors' success related to the presence of certain individuals in their team ? If yes, how frequently have they been collaborating with each other ?\n",
    "\n",
    "What is maybe more interesting is, instead of looking at the entirety of the crew, to see how much directors tend to keep some 'elements' of their crew : what we could consider as their core crew members. Maybe one, two or more people that are constantly there in between films. This helps, in contrary to the overall overlap coefficient, to assess the impact of particular relationships.\n",
    "\n",
    "We will very simply try to check this by searching for the members that are present in the director's films. First, let's see how many directors had relationships with people that they maintained during at least 80% of the films they directed and that we have information about :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_core_crew(directors_copy, movie_crews, movies, success_threshold, core_threshold, only_successes):\n",
    "    if only_successes :\n",
    "        directors_with_at_least_threshold_movies = directors_copy[directors_copy['directed_movies'].apply(lambda x: len(str(x).split(',')) >= success_threshold)]\n",
    "    else :\n",
    "        directors_with_at_least_threshold_movies = directors_copy\n",
    "    directors_core = directors_with_at_least_threshold_movies.copy()\n",
    "    directors_core['core_crew'] = None\n",
    "\n",
    "    for index, row in tqdm(directors_core.iterrows(), total=len(directors_core), desc=f\"Identifying core members in directors' films (Threshold: {core_threshold*100} %)\"):\n",
    "        director_id = index\n",
    "        directed_movies_str = row['directed_movies']\n",
    "\n",
    "        directed_movies = directed_movies_str.split(',')\n",
    "\n",
    "        if only_successes :\n",
    "            top_movies_count = min(success_threshold, len(directed_movies))\n",
    "        \n",
    "        else :\n",
    "            top_movies_count = len(directed_movies)\n",
    "\n",
    "        top_movies = (\n",
    "            pd.DataFrame(directed_movies, columns=['tconst'])\n",
    "            .merge(movies[['score']], left_on='tconst', right_index=True)\n",
    "            .nlargest(top_movies_count, 'score')\n",
    "        )\n",
    "\n",
    "        director_crews = [set(movie_crews[movie_id]) for movie_id in top_movies['tconst'] if movie_id in movie_crews]\n",
    "\n",
    "        total_movie_count = len(top_movies)\n",
    "        all_crew_members = [crew_member for crew_set in director_crews for crew_member in crew_set if crew_member != director_id]\n",
    "        crew_member_counts = Counter(all_crew_members)\n",
    "\n",
    "        core_crew = [crew_member for crew_member, count in crew_member_counts.items() if count >= core_threshold * total_movie_count]\n",
    "\n",
    "        directors_core.at[index, 'core_crew'] = core_crew\n",
    "    \n",
    "    return directors_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ff64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_core = identify_core_crew(directors_copy,movie_crews,movies,100,0.8,False)\n",
    "dir_core['core_crew_count'] = dir_core['core_crew'].apply(lambda x: len(str(x).split(',')) if x else 0)\n",
    "dir_core.sort_values(by='avg-5',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97650a86",
   "metadata": {},
   "source": [
    "Well, once again, we see that there are changes in crew members across the films : Only the Cohen Brothers have a core relationship, but it is of course with each other. There is nothing much to analyse here.\n",
    "\n",
    "Rather, we're interested about **success** of the directors. Let us thus see if some persons are often present in their successes :\n",
    "\n",
    "Here, we take the 5 best films (in terms of score) of the directors and identify if some crew members were present in at least 4 of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_core = identify_core_crew(directors_copy,movie_crews,movies,5,0.8,True)\n",
    "\n",
    "directors_core['core_crew_count'] = directors_core['core_crew'].apply(lambda x: len(str(x).split(',')) if x else 0)\n",
    "directors_core.sort_values(by='avg-5',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ddb4bf",
   "metadata": {},
   "source": [
    "Now, that's more like it ! We have some 'core relationships'. However, results are mixed. Some of the most successful directors indeed have some very close relationships, but some do not. It however seems that the 'core_crew' size is either way pretty reduced. One exception shown above is Peter Jackson, which is normal as LOTR is a trilogy with essentially the same people working on it each time.\n",
    "\n",
    "But interesting results here still :\n",
    "\n",
    "- Nolan & Fincher : Their wives are in these core relationships\n",
    "\n",
    "- Spielberg & Miyazaki (for instance) : Some famous composers : John Williams and Joe Hisaishi \n",
    "\n",
    "- Cohen Brothers : They of course share the same core crew members\n",
    "\n",
    "\n",
    "From this only, the 'landscape' of core relationships seems complex to analyse. Let's see if the number of these core relationships has an impact on the score. We drop outliers such as Peter Jackson to have an better insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce09703",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = directors_core[directors_core['core_crew_count'] < 50].dropna(subset=('avg-5','core_crew_count'))\n",
    "test['avg-5'] = pd.to_numeric(test['avg-5'])\n",
    "model = smf.ols('Q(\"avg-5\") ~ core_crew_count', data=test).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496bc509",
   "metadata": {},
   "source": [
    "The R^2 squared is terrible, but slight (significant) positive correlation between the number of core relationships and the success metric of the director. \n",
    "From this simple model, it seems that the nb of close relationships of directors with members of the industry over their best films seem to have a slight correlation with success. \n",
    "\n",
    "To have more insights, we take a look at the difference in core crew relationships following certain thresholds of success score of directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ouep = test.copy(deep=True)\n",
    "ouep['avg-5'] = pd.to_numeric(ouep['avg-5'], errors='coerce')\n",
    "\n",
    "\n",
    "def update_plot(threshold):\n",
    "    \n",
    "    ouep['Score Category'] = pd.cut(ouep['avg-5'], bins=[-float('inf'), threshold, float('inf')],\n",
    "                                    labels=['<25', '>25'], right=False)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.pointplot(x='Score Category', y='core_crew_count', data=ouep, errorbar=('ci', 95),color=PALETTE_D[1])\n",
    "\n",
    "    # Set plot labels and title dynamically\n",
    "    plt.xlabel(f'Success score Category (Threshold = {threshold:.2f})')\n",
    "    plt.ylabel('Average core_crew_count')\n",
    "    plt.title(f'Average core_crew_count for Directors (Threshold = {threshold:.2f})')\n",
    "\n",
    "    # Update x-axis labels dynamically\n",
    "    plt.xticks(ticks=plt.xticks()[0], labels=[f'<{threshold:.2f}', f'>{threshold:.2f}'])\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive slider for the threshold value\n",
    "threshold_slider = widgets.FloatSlider(value=30, min=20, max=40, step=1,\n",
    "                                      description='Threshold')\n",
    "# Create the interactive plot\n",
    "interact(update_plot, threshold=threshold_slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bc82c",
   "metadata": {},
   "source": [
    "Although that of course does not mean causation, there seems to be a difference in core relationships number between successful directors and those that are not, whatever we decide to set the 'threshold' for success at.\n",
    "\n",
    "However, let us be sure that this is not cofounded by the number of movies directed by a certain director : maybe it could just be that directors that directed more movies are more successful overall ?\n",
    "\n",
    "We will balance the dataset with similar number of movies directed :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = test[test['avg-5'] < 30]\n",
    "treatment_df = test[test['avg-5'] >= 30]\n",
    "print(len(treatment_df), 'directors that are successful (treatment group).')\n",
    "print(len(control_df), 'directors that are not successful (control group).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71726291",
   "metadata": {},
   "source": [
    "~5mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for treatment_id, treatment_row in treatment_df.iterrows():\n",
    "    for control_id, control_row in control_df.iterrows():\n",
    "        nmd_similarity = np.abs(len(treatment_row['directed_movies'].split(',')) - len(control_row['directed_movies'].split(',')) )\n",
    "        G.add_weighted_edges_from([(control_id, treatment_id, nmd_similarity)])\n",
    "        \n",
    "matching = nx.min_weight_matching(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ecafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = [i[0] for i in list(matching)] + [i[1] for i in list(matching)]\n",
    "matched_test = test.loc[matched]\n",
    "len(matched_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the DataFrame\n",
    "ouep = matched_test.copy()\n",
    "\n",
    "# Convert 'avg-5' column to numeric\n",
    "ouep['avg-5'] = pd.to_numeric(ouep['avg-5'], errors='coerce')\n",
    "\n",
    "# Function to update and plot based on the threshold value\n",
    "def update_plot(threshold):\n",
    "    # Create a new column to categorize directors based on the condition\n",
    "    ouep['Score Category'] = pd.cut(ouep['avg-5'], bins=[-float('inf'), threshold, float('inf')],\n",
    "                                    labels=['<25', '>25'], right=False)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.pointplot(x='Score Category', y='core_crew_count', data=ouep, errorbar=('ci', 95),color=PALETTE_D[1])\n",
    "\n",
    "    # Set plot labels and title dynamically\n",
    "    plt.xlabel(f'Success score Category (Threshold = {threshold:.2f})')\n",
    "    plt.ylabel('Average core_crew_count')\n",
    "    plt.title(f'Average core_crew_count for Directors (Threshold = {threshold:.2f})')\n",
    "\n",
    "    # Update x-axis labels dynamically\n",
    "    plt.xticks(ticks=plt.xticks()[0], labels=['Unsuccessful', 'Successful'])\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive slider for the threshold value\n",
    "threshold_slider = widgets.FloatSlider(value=30, min=20, max=40, step=1,\n",
    "                                      description='Threshold')\n",
    "# Create the interactive plot\n",
    "interact(update_plot, threshold=threshold_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370e0d2",
   "metadata": {},
   "source": [
    "The difference and no-overlap of the 95CI% intervals is still present afterwards ! A statistical test to further check it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_statistic, p_value = ttest_rel(matched_test[matched_test['avg-5'] <30]['core_crew_count'], matched_test[matched_test['avg-5'] >=30]['core_crew_count'])\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in accuracy is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in accuracy is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30f456",
   "metadata": {},
   "source": [
    "The difference between our two balanced groups is still statistically significant ! There is a significant difference in members in the core crew between successful directors and unsuccessful directors. Even when matching for the number of movies directed, the null hypothesis that the average core crew size between successful and unsuccessful directors most likely cannot only be explained by chance.\n",
    "\n",
    "Now, the number of core relations is one thing, but what can be interesting to see is if the 'type' of people in this core crew has an impact as well. Do directors that have writers in their core crew have more success ? What about artistic/visual effects leads ? Even actors or actresses ?\n",
    "\n",
    "How is success of directors related to the professions of people in their core crew ? (We one-hot encode variable for profession, 0 if the profession is not part of the core crew of the director, 1 if it is) ~4mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mip = mip_enhanced.set_index('nconst')\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in directors_core dataframe\n",
    "for index, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    director_id = index\n",
    "    core_crew_list = row['core_crew']\n",
    "\n",
    "    # Find the corresponding rows in mip_enhanced\n",
    "    crew_member_rows = mip[mip.index.isin(core_crew_list)]\n",
    "    # Flatten and unique list of professions\n",
    "    professions = crew_member_rows['primaryProfession'].str.split(',').explode().unique()\n",
    "\n",
    "    # Create a temporary dataframe for the current director\n",
    "    temp_df = pd.DataFrame({'nconst': director_id}, index=[0])\n",
    "    # Create binary columns indicating presence of each profession\n",
    "    for profession in professions:\n",
    "            if pd.notna(profession):\n",
    "                cleaned_profession = ''.join(e for e in profession if e.isalnum())\n",
    "                temp_df[cleaned_profession] = int(1)\n",
    "\n",
    "    # Append the temporary dataframe to the result dataframe\n",
    "    result_df = pd.concat([result_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "result_df = result_df.fillna(int(0))\n",
    "\n",
    "final_result = pd.merge(test, result_df, on='nconst', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the values in each column\n",
    "#result_df = result_df.set_index('nconst')\n",
    "profession_counts = result_df.sum()\n",
    "\n",
    "\n",
    "# Set the presence threshold\n",
    "presence_threshold = 0.02\n",
    "\n",
    "# Identify professions with at least the specified presence\n",
    "filtered_professions = profession_counts[profession_counts / profession_counts.sum() >= presence_threshold]\n",
    "others = profession_counts[profession_counts / profession_counts.sum() < presence_threshold]\n",
    "\n",
    "sorted_profession_counts = profession_counts.sort_values(ascending=False)\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "color_mapping = dict(zip(filtered_professions.index, PALETTE_D + ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# Plot the bar chart on the first subplot\n",
    "ax1.bar(sorted_profession_counts.index, sorted_profession_counts, color=[color_mapping.get(label, 'lightgray') for label in sorted_profession_counts.index])\n",
    "\n",
    "ax1.set_title('Distribution of Professions in Core Crew of Directors', fontsize=14)\n",
    "ax1.set_xlabel('Professions')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Plot the pie chart on the second subplot\n",
    "combined_profession_counts = filtered_professions.copy()\n",
    "combined_profession_counts['other'] = others.sum()\n",
    "\n",
    "# Plot the pie chart\n",
    "ax2.pie(combined_profession_counts, labels=combined_profession_counts.index, autopct='%1.1f%%', colors=[color_mapping.get(label, 'lightgray') for label in combined_profession_counts.index])\n",
    "\n",
    "# Customize the appearance of the pie chart\n",
    "ax2.set_title('Percentage of Professions in Core Crew', fontsize=14)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3d047",
   "metadata": {},
   "source": [
    "The three professions that are the most present in the core crew of directors are producers, writers, as well as actors. At 4th, we can also see that ~9% of the directors we selected have collaborated pretty closely with other directors.\n",
    "Then, we also have professions in the 'sound' domain : soundtrack, musicdepartment & composer namely, which are also present to a certain extent in the director's crews.\n",
    "\n",
    "Interestingly, actresses are way less presents than actors : sign of a man-dominated industry.\n",
    "\n",
    "Cinematographers are also present.\n",
    "\n",
    "We then have also a lot of others but that are present in extremely few quantity : we cannot draw any conclusions using them on the success of a director that maybe have them in its crew. We only have 'famous' cinema jobs in these collaborations : all the shadow jobs do not seem well represented. However, this can also come from the lack of complete and throrough information on the complete crew of films. We only have what's more valorized through IMDb, this can be important to mention as a potential bias in our analysis of this part in particular.\n",
    "\n",
    "However, we can take the main jobs present above and try to see if some of them are more linked with director's success : Producer, Writer, Actor, Director, Soundtrack, MusicDepartment, Composer, Cinematographer, Cameradepartment, AssistantDirector and editiorialdepartment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbda3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = pd.merge(directors_core['avg-5'], result_df, left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'avg-5' to numeric type\n",
    "ml_df['avg-5'] = pd.to_numeric(ml_df['avg-5'], errors='coerce')\n",
    "\n",
    "filtered_data = ml_df[['avg-5', 'producer', 'writer', 'actor', 'director', 'soundtrack','musicdepartment','composer', 'cinematographer','cameradepartment','editor','editorialdepartment', 'assistantdirector', 'actress', 'productionmanager']]\n",
    "\n",
    "avg_scores = {}\n",
    "for profession in filtered_data.columns[1:]:\n",
    "    avg_score = filtered_data[filtered_data[profession] == 1.0]['avg-5'].mean()\n",
    "    avg_scores[profession] = avg_score\n",
    "\n",
    "data_for_analysis = pd.DataFrame(columns=['Profession', 'avg-5'])\n",
    "for profession in avg_scores.keys():\n",
    "    data_for_analysis = pd.concat([data_for_analysis, filtered_data[filtered_data[profession] == 1.0][['avg-5']].assign(Profession=profession)])\n",
    "\n",
    "# Perform Tukey's HSD test for multiple comparisons !!\n",
    "tukey_results = pairwise_tukeyhsd(data_for_analysis['avg-5'], data_for_analysis['Profession'], alpha=0.05)\n",
    "\n",
    "# Plot the results\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=list(avg_scores.keys()), y=list(avg_scores.values()),color=PALETTE_D[1])\n",
    "\n",
    "# 95CI barssss\n",
    "for i, profession in enumerate(avg_scores.keys()):\n",
    "    ci = tukey_results.meandiffs[i]\n",
    "    plt.errorbar(i, avg_scores[profession], yerr=abs(ci), fmt='none', color='black', capsize=5)\n",
    "\n",
    "# Stars for significant differences\n",
    "for i, pvalue in enumerate(tukey_results.pvalues < 0.05):\n",
    "    if pvalue:\n",
    "        plt.text(i, max(avg_scores.values()) + 0.15, '*', ha='center', va='center', fontdict={'weight': 'bold'})\n",
    "\n",
    "plt.xlabel('Profession')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Average avg-5 Score')\n",
    "plt.title('Average avg-5 Score for Selected Professions with 95% CI and Significant Differences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75cba4d",
   "metadata": {},
   "source": [
    "No significant differences between any of the professions in terms of the avg-5 score, in the core crew of the director.\n",
    "\n",
    "--> The type of people in the core crew is not sufficient to explain the success : chemistry is something else than association of jobs !\n",
    "\n",
    "-----\n",
    "### Are some directors successful only because they cast popular actors ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_and_actresses = pd.DataFrame(jobs_principal_people[jobs_principal_people['category'].isin(['actor', 'actress'])]['nconst'].unique()).rename(columns={0:'nconst'})\n",
    "\n",
    "# Count the number of movies for each actor in jobs_principal_people\n",
    "actor_movie_counts = jobs_principal_people[jobs_principal_people['category'].isin(['actor', 'actress'])].groupby('nconst')['tconst'].count()\n",
    "\n",
    "# Filter out actors who have less than 3 movies\n",
    "valid_actors_initial = actor_movie_counts[actor_movie_counts >= 3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the scores for each people and each movie\n",
    "tmp_mip = mip_enhanced[mip_enhanced['nconst'].isin(valid_actors_initial)].copy()\n",
    "tmp_mip = pd.merge(tmp_mip,actors_and_actresses,on='nconst')\n",
    "tmp_mip['known_titles_list'] = tmp_mip['knownForTitles'].str.split(',')\n",
    "exploded_people_df = tmp_mip.explode('known_titles_list')\n",
    "merged_df = pd.merge(exploded_people_df, movies, left_on='known_titles_list', right_index=True, how='left')\n",
    "merged_df['score'] = pd.to_numeric(merged_df['score'], errors='coerce')\n",
    "\n",
    "# Filter out NaN scores\n",
    "merged_df_filtered = merged_df.dropna(subset=['score'])\n",
    "# Calculate the number of movies per person, filter to keep only the ones with a sufficient number of movies played in\n",
    "movie_count_per_person = merged_df_filtered.groupby('nconst')['score'].count()\n",
    "valid_people = movie_count_per_person[movie_count_per_person >= 3].index\n",
    "# Filter the merged dataframe for valid people\n",
    "valid_merged_df = merged_df_filtered[merged_df_filtered['nconst'].isin(valid_people)]\n",
    "# Calculate the number of movies per person in the original movies dataframe\n",
    "movie_count_per_person_original = valid_merged_df.groupby('nconst').size()\n",
    "\n",
    "# Filter out individuals with less than 3 movies in the original movies dataframe\n",
    "final_valid_people = movie_count_per_person_original[movie_count_per_person_original >= 3].index\n",
    "\n",
    "# Filter the merged dataframe for final valid people\n",
    "final_valid_merged_df = valid_merged_df[valid_merged_df['nconst'].isin(final_valid_people)]\n",
    "\n",
    "# Calculate the average score and primary name for each person\n",
    "average_scores = final_valid_merged_df.groupby('nconst').agg({'score': 'mean', 'primaryName': 'first'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2219809",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores.sort_values(by = 'score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c573b7",
   "metadata": {},
   "source": [
    "We have a list of only actors/actresses that played in several movies being part of the main cast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a854de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_collabs = {director: {actoress: collaborations for actoress, collaborations in data.items() if actoress in average_scores.index} for director, data in collab_counts.items()}\n",
    "actors_collabs = {director: data for director, data in actors_collabs.items() if director in directors_copy.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58169a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_score_mapping = dict(zip(average_scores.index, average_scores['score']))\n",
    "\n",
    "directors_avg_score = {}\n",
    "for director, collaborations in actors_collabs.items():\n",
    "    total_score = 0\n",
    "    total_collaborations = 0\n",
    "    for actor, collaborations_count in collaborations.items():\n",
    "        if actor in actor_score_mapping:\n",
    "            total_score += actor_score_mapping[actor] * collaborations_count\n",
    "            total_collaborations += collaborations_count\n",
    "    if total_collaborations >= 3:\n",
    "        directors_avg_score[director] = total_score / total_collaborations\n",
    "\n",
    "# Create a DataFrame for directors and their average scores\n",
    "directors_df = pd.DataFrame(list(directors_avg_score.items()), columns=['director', 'average_score'])\n",
    "\n",
    "# Merge the directors_df with our directors' success scores\n",
    "merged_df = directors_df.merge(directors_copy, left_on='director', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.regplot(x='average_score', y='avg-3', data=merged_df, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[0]})\n",
    "\n",
    "correlation_coefficient = merged_df['average_score'].corr(merged_df['avg-3'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color='red')\n",
    "plt.title('-')\n",
    "plt.xlabel('Average score of the actors')\n",
    "plt.ylabel('avg-3 score of the directors')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "There seem to be an increase --> then : Directors only successful because they cast successful actors ? \n",
    "\n",
    "But successful actors basically mainly works with successful directors... The chicken or the egg ?\n",
    "\n",
    "Let's try to perform a graph between directors and actors only : We already suppressed people that are not lead actors/actresses from the equation and we also remove all potential links in between directors.\n",
    "\n",
    "This way, we have a actors/actresses <--> directors bipartite graph. The number of nodes and edges is going to be huge, and to see how successful directors are similar in terms of successful actors/actresses they cast, we can use the bipartite projection of this graph on director's nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_bipartite_projection(collab_counts,wanted_directors,all_directors) :\n",
    "    \n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    directors_set = set()\n",
    "    collaborators_set = set()\n",
    "\n",
    "    for director, collaborators in tqdm(collab_counts.items(),total=len(collab_counts),desc=\"Building a graph of all collaborations\"):\n",
    "        if director in wanted_directors :\n",
    "            if director not in directors_set:\n",
    "                graph.add_node(director, bipartite=0)\n",
    "                directors_set.add(director)\n",
    "\n",
    "            for collaborator, collaborations_count in collaborators.items():\n",
    "                if ((collaborator not in all_directors) & (collaborator not in wanted_directors)) :\n",
    "                    if collaborator not in collaborators_set:\n",
    "                        graph.add_node(collaborator, bipartite=1)\n",
    "                        collaborators_set.add(collaborator)\n",
    "\n",
    "                    if collaborator not in collab_counts.keys() : \n",
    "                        if ((collaborator not in all_directors) & (collaborator not in wanted_directors)) :\n",
    "                            graph.add_edge(director, collaborator, weight=collaborations_count)\n",
    "    print('The Graph is Bipartite :', str(bipartite.is_bipartite(graph)))          \n",
    "    directors_nodes = {node for node, data in graph.nodes(data=True) if data['bipartite'] == 0}\n",
    "    directors_projection = nx.bipartite.weighted_projected_graph(graph, directors_nodes, ratio=False)\n",
    "\n",
    "    return(graph, directors_nodes,directors_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_collab_graph, proj_directors_nodes, curr_act_dict_proj = building_bipartite_projection(actors_collabs,directors_copy.index,directors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "subgraph = curr_act_dict_proj.subgraph(directors_copy.sort_values(by='avg-3',ascending=False).head(20).index.to_list())\n",
    "edge_weights = nx.get_edge_attributes(subgraph, 'weight')\n",
    "\n",
    "\n",
    "# Draw the subgraph\n",
    "scaler = MinMaxScaler(feature_range=(0.5, 4))\n",
    "normalized_weights = scaler.fit_transform([[w] for w in edge_weights.values()])\n",
    "normalized_weights = {edge: weight[0] for edge, weight in zip(edge_weights.keys(), normalized_weights)}\n",
    "\n",
    "\n",
    "global_min = directors_copy['avg-3'].min()\n",
    "global_max = directors_copy['avg-3'].max()\n",
    "\n",
    "cmap = PALETTE_C\n",
    "norm = Normalize(vmin=global_min, vmax=global_max) \n",
    "\n",
    "\n",
    "# Normalize edge weights by dividing by the maximum weight\n",
    "pos = nx.circular_layout(subgraph)\n",
    "edge_widths = [normalized_weights[edge] for edge in subgraph.edges]\n",
    "\n",
    "labels = {node: directors.loc[node, 'primaryName'] for node in subgraph.nodes}\n",
    "\n",
    "node_colors = directors_copy.loc[list(subgraph.nodes), 'avg-3']\n",
    "normalized_values = norm(node_colors)\n",
    "\n",
    "# Map normalized values to colors using the colormap\n",
    "node_colors_mapped = [cmap(value) for value in normalized_values]\n",
    "\n",
    "\n",
    "node_collection = nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors_mapped, node_size=100)\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='black', width=edge_widths)\n",
    "#nx.draw_networkx_labels(subgraph, pos, labels=labels, font_weight='bold')\n",
    "label_pos = {k: (v[0] + 0.2 * pos[k][0], v[1] + 0.1 * pos[k][1]) for k, v in pos.items()}\n",
    "for node, (x, y) in label_pos.items():\n",
    "        plt.text(x, y, labels[node], ha='center', va='center', fontweight='light', fontsize=10)\n",
    "\n",
    "\n",
    "plt.grid(False)\n",
    "plt.gca().set_frame_on(False)\n",
    "cbar_label = 'Directors Success Score'\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Empty array for the data range\n",
    "cbar = plt.colorbar(sm,ax=plt.gca())\n",
    "cbar.ax.set_position([0.825, 0.1, 0.02, 0.8])\n",
    "cbar.set_label(cbar_label)\n",
    "cbar.ax.set_ylim(global_min, global_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efbd67e",
   "metadata": {},
   "source": [
    "The most famous directors are hyper-connected in terms of collaborations they share with different actors. How does it evolve ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7156d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_directors(start_index):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    end_index = start_index + 20\n",
    "    selected_directors = directors_copy.dropna(subset='avg-3').sort_values(by='avg-3', ascending=False).iloc[start_index:end_index]\n",
    "    subgraph = curr_act_dict_proj.subgraph(selected_directors.index.to_list())\n",
    "    edge_weights = nx.get_edge_attributes(subgraph, 'weight')\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0.5, 4))\n",
    "    normalized_weights = scaler.fit_transform([[w] for w in edge_weights.values()])\n",
    "    normalized_weights = {edge: weight[0] for edge, weight in zip(edge_weights.keys(), normalized_weights)}\n",
    "\n",
    "    global_min = directors_copy['avg-3'].min()\n",
    "    global_max = directors_copy['avg-3'].max()\n",
    "\n",
    "    cmap = PALETTE_C\n",
    "    norm = Normalize(vmin=global_min, vmax=global_max)\n",
    "\n",
    "    pos = nx.circular_layout(subgraph)\n",
    "    edge_widths = [normalized_weights[edge] for edge in subgraph.edges]\n",
    "\n",
    "    labels = {node: directors.loc[node, 'primaryName'] for node in subgraph.nodes}\n",
    "\n",
    "    node_colors = directors_copy.loc[list(subgraph.nodes), 'avg-3']\n",
    "    normalized_values = norm(node_colors)\n",
    "\n",
    "    node_colors_mapped = [cmap(value) for value in normalized_values]\n",
    "\n",
    "    node_collection = nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors_mapped, node_size=100)\n",
    "    nx.draw_networkx_edges(subgraph, pos, edge_color='black', width=edge_widths)\n",
    "\n",
    "    label_pos = {k: (v[0] + 0.2 * pos[k][0], v[1] + 0.1 * pos[k][1]) for k, v in pos.items()}\n",
    "    for node, (x, y) in label_pos.items():\n",
    "        plt.text(x, y, labels[node], ha='center', va='center', fontweight='light', fontsize=10)\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.gca().set_frame_on(False)\n",
    "    cbar_label = 'Directors Success Score'\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  \n",
    "    cbar = plt.colorbar(sm, ax=plt.gca())\n",
    "    cbar.ax.set_ylim(global_min, global_max)\n",
    "    cbar.set_label(cbar_label)\n",
    "    cbar.ax.set_position([0.825, 0.1, 0.02, 0.8])\n",
    "    cbar.outline.set_visible(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_index in [20,60,100,400,1000,1500,2000,2500]:\n",
    "    plot_directors(start_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4213df5",
   "metadata": {},
   "source": [
    "As expected, the more 'unsuccessful' the directors are, the less connections they harbor with other directors. Some relationships might happen still, but generally the most 'full' graphs in terms of edges are found when successful directors are present.\n",
    "\n",
    "\n",
    "Let's see intersting things for the most successful ones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_keys = set(actors_collabs['nm0000631'].keys()) & set(actors_collabs['nm0000229'].keys())\n",
    "\n",
    "# Find common items (key-value pairs)\n",
    "common_items = set(actors_collabs['nm0000631'].items()) & set(actors_collabs['nm0000229'].items())\n",
    "\n",
    "print(\"Common actor collaboration:\", common_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores.loc[list(common_keys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e73414",
   "metadata": {},
   "source": [
    "Ridley scott & Steven Spielberg share a lot of actors, and their score indicates, they majoritarely are successful actors, with very famous names such as DiCaprio, Harisson Ford, Anthony Hopkins, Tom Cruise amongst the most well known.\n",
    "\n",
    "Directors that, at first sight, even though both extremely brilliant seem to have nothing to have in common in terms of their universe and time in activity : Miyazaki & both Hitchock. They still have a common collaboration when looking at the graph above :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_keys = set(actors_collabs['nm0594503'].keys()) & set(actors_collabs['nm0000033'].keys())\n",
    "\n",
    "# Find common items (key-value pairs)\n",
    "common_items = set(actors_collabs['nm0594503'].items()) & set(actors_collabs['nm0000033'].items())\n",
    "\n",
    "print(\"Common actor collaboration:\", common_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores.loc[list(common_keys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986bd8c",
   "metadata": {},
   "source": [
    "Suzanne Pleshette actually worked as a voice actress on the english version of Spirited Away but also stars a main role of 'The Birds' by Hitchcock. Of course, this is only a voice actor for the english version of the movie which may not have directly been by Miyazaki itself. However the choices surely have been made with Studio Ghibli, and it still shows that successful actors play a role in the success of the movies worldwide even for movies that come from overseas !\n",
    "\n",
    "\n",
    "Connections are inevitable : we can see that in terms of actors, very successful directors have a tendency to be connected to each other in terms of actors/actresses they star in their films.\n",
    "\n",
    "Now let's do the same thing, but for the entire collaborations that we have found, not only actors. One node per director and by person in the many different crews, the edge linking the both being weighted by their number of collaborations. The graph is once again constructed in such a manner that directors-directors (if two directors direct the same films) are not counted in the graph : ONLY crew-directors interactions --> bipartite graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f07f2",
   "metadata": {},
   "source": [
    "Function is defined to build this bipartite projection for only the directors that we want (inclusion of 'all_directors' is to not add edges between two directors). (Takes ~10 mins to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907be8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_collab_graph, all_directors_nodes, all_bip_proj = building_bipartite_projection(collab_counts,directors_copy.index,directors.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01d76e",
   "metadata": {},
   "source": [
    "The original graph, given its size and the number of edges, is useless to display : we can not really even see what it's all about. Let's thus look at what we obtain for the bipartite projection of our most successful directors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be275f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "subgraph = all_bip_proj.subgraph(directors_copy.sort_values(by='avg-3',ascending=False).head(20).index.to_list())\n",
    "edge_weights = nx.get_edge_attributes(subgraph, 'weight')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0.5, 4))\n",
    "normalized_weights = scaler.fit_transform([[w] for w in edge_weights.values()])\n",
    "normalized_weights = {edge: weight[0] for edge, weight in zip(edge_weights.keys(), normalized_weights)}\n",
    "\n",
    "\n",
    "global_min = directors_copy['avg-3'].min()\n",
    "global_max = directors_copy['avg-3'].max()\n",
    "\n",
    "cmap = PALETTE_C \n",
    "norm = Normalize(vmin=global_min, vmax=global_max) \n",
    "\n",
    "pos = nx.circular_layout(subgraph)\n",
    "edge_widths = [normalized_weights[edge] for edge in subgraph.edges]\n",
    "\n",
    "labels = {node: directors.loc[node, 'primaryName'] for node in subgraph.nodes}\n",
    "\n",
    "node_colors = directors_copy.loc[list(subgraph.nodes), 'avg-3']\n",
    "normalized_values = norm(node_colors)\n",
    "\n",
    "node_colors_mapped = [cmap(value) for value in normalized_values]\n",
    "\n",
    "\n",
    "node_collection = nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors_mapped, node_size=100)\n",
    "\n",
    "label_pos = {k: (v[0] + 0.2 * pos[k][0], v[1] + 0.1 * pos[k][1]) for k, v in pos.items()}\n",
    "for node, (x, y) in label_pos.items():\n",
    "        plt.text(x, y, labels[node], ha='center', va='center', fontweight='light', fontsize=10)\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='black', width=edge_widths)\n",
    "#nx.draw_networkx_labels(subgraph, pos, labels=labels, font_weight='bold')\n",
    "\n",
    "plt.gca().set_frame_on(False)\n",
    "plt.grid(False)\n",
    "cbar_label = 'Directors Success Score'\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Empty array for the data range\n",
    "cbar = plt.colorbar(sm,ax=plt.gca())\n",
    "cbar.ax.set_position([0.825, 0.1, 0.02, 0.8])\n",
    "cbar.ax.set_ylim(global_min, global_max)\n",
    "cbar.set_label(cbar_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61819727",
   "metadata": {},
   "source": [
    "Successful directors share relationships it seems! Let's try even bigger :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd052628",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "subgraph = all_bip_proj.subgraph(directors_copy.sort_values(by='avg-3',ascending=False).head(40).index.to_list())\n",
    "edge_weights = nx.get_edge_attributes(subgraph, 'weight')\n",
    "\n",
    "\n",
    "# Draw the subgraph\n",
    "scaler = MinMaxScaler(feature_range=(0.5, 4))\n",
    "normalized_weights = scaler.fit_transform([[w] for w in edge_weights.values()])\n",
    "normalized_weights = {edge: weight[0] for edge, weight in zip(edge_weights.keys(), normalized_weights)}\n",
    "\n",
    "\n",
    "global_min = directors_copy['avg-3'].min()\n",
    "global_max = directors_copy['avg-3'].max()\n",
    "\n",
    "cmap = PALETTE_C   # Replace 'viridis' with your desired colormap\n",
    "norm = Normalize(vmin=global_min, vmax=global_max) \n",
    "\n",
    "\n",
    "# Normalize edge weights by dividing by the maximum weight\n",
    "pos = nx.circular_layout(subgraph)\n",
    "edge_widths = [normalized_weights[edge] for edge in subgraph.edges]\n",
    "\n",
    "labels = {node: directors.loc[node, 'primaryName'] for node in subgraph.nodes}\n",
    "\n",
    "node_colors = directors_copy.loc[list(subgraph.nodes), 'avg-3']\n",
    "normalized_values = norm(node_colors)\n",
    "\n",
    "# Map normalized values to colors using the colormap\n",
    "node_colors_mapped = [cmap(value) for value in normalized_values]\n",
    "\n",
    "\n",
    "node_collection = nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors_mapped, node_size=100)\n",
    "nx.draw_networkx_edges(subgraph, pos, edge_color='black', width=edge_widths)\n",
    "#nx.draw_networkx_labels(subgraph, pos, labels=labels, font_weight='bold')\n",
    "label_pos = {k: (v[0] + 0.25 * pos[k][0], v[1] + 0.15 * pos[k][1]) for k, v in pos.items()}\n",
    "\n",
    "for node, (x, y) in label_pos.items():\n",
    "            #print(x,y)\n",
    "            # Increase y-coordinate for nodes at the top\n",
    "            if y > 1.14:\n",
    "                y += 0.05\n",
    "            # Decrease y-coordinate for nodes at the bottom\n",
    "            elif y < -1.14:\n",
    "                y -= 0.05\n",
    "            plt.text(x, y, labels[node], ha='center', va='center', fontweight='light', fontsize=10)\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "cbar_label = 'Directors Success Score'\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Empty array for the data range\n",
    "cbar = plt.colorbar(sm,ax=plt.gca())\n",
    "plt.gca().set_frame_on(False)\n",
    "cbar.ax.set_position([0.825, 0.1, 0.02, 0.8])\n",
    "cbar.ax.set_ylim(global_min, global_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95bf54",
   "metadata": {},
   "source": [
    "Seems like it works well, some relationships are way heavier than others depending on the similarities of the collaborations they had throughout their careers. Here we can see that the Wachovski sisters & the Cohen brothers have very much heavier links towards each other than with the rest (improve the visualization).\n",
    "Overall however, these successful directors seem very well connected !\n",
    "\n",
    "What about unsuccessful ones ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_directors(start_index):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    end_index = start_index + 40\n",
    "    selected_directors = directors_copy.dropna(subset='avg-3').sort_values(by='avg-3', ascending=False).iloc[start_index:end_index]\n",
    "    subgraph = all_bip_proj.subgraph(selected_directors.index.to_list())\n",
    "    edge_weights = nx.get_edge_attributes(subgraph, 'weight')\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0.5, 4))\n",
    "    normalized_weights = scaler.fit_transform([[w] for w in edge_weights.values()])\n",
    "    normalized_weights = {edge: weight[0] for edge, weight in zip(edge_weights.keys(), normalized_weights)}\n",
    "\n",
    "    global_min = directors_copy['avg-3'].min()\n",
    "    global_max = directors_copy['avg-3'].max()\n",
    "\n",
    "    cmap = PALETTE_C\n",
    "    norm = Normalize(vmin=global_min, vmax=global_max)\n",
    "\n",
    "    pos = nx.circular_layout(subgraph)\n",
    "    edge_widths = [normalized_weights[edge] for edge in subgraph.edges]\n",
    "\n",
    "    labels = {node: directors.loc[node, 'primaryName'] for node in subgraph.nodes}\n",
    "\n",
    "    node_colors = directors_copy.loc[list(subgraph.nodes), 'avg-3']\n",
    "    normalized_values = norm(node_colors)\n",
    "\n",
    "    node_colors_mapped = [cmap(value) for value in normalized_values]\n",
    "\n",
    "    node_collection = nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors_mapped, node_size=100)\n",
    "    nx.draw_networkx_edges(subgraph, pos, edge_color='black', width=edge_widths)\n",
    "\n",
    "    label_pos = {k: (v[0] + 0.2 * pos[k][0], v[1] + 0.1 * pos[k][1]) for k, v in pos.items()}\n",
    "    for node, (x, y) in label_pos.items():\n",
    "        if y > 1.09 :\n",
    "            y+=0.05\n",
    "        if y <-1.09 :\n",
    "            y-= 0.05\n",
    "        plt.text(x, y, labels[node], ha='center', va='center', fontweight='light', fontsize=10)\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.gca().set_frame_on(False)\n",
    "    cbar_label = 'Directors Success Score'\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  \n",
    "    cbar = plt.colorbar(sm, ax=plt.gca())\n",
    "    cbar.ax.set_ylim(global_min, global_max)\n",
    "    cbar.set_label(cbar_label)\n",
    "    cbar.ax.set_position([0.825, 0.1, 0.02, 0.8])\n",
    "    cbar.outline.set_visible(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f00500",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_index in [0,20,60,100,400,1000,1500,2000,2500]:\n",
    "    plot_all_directors(start_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1cbd0",
   "metadata": {},
   "source": [
    "Much less shared collaborations between unsuccessful directors.\n",
    "\n",
    "Very few relationships, looks nothing like what we saw above. There seems like there is a real difference : Unsuccessful directors have very few common crew members, while successful ones seems to be sharing a lot of them.\n",
    "\n",
    "Therefore, In that bipartite graph, let's try to find the directors with the highest degree centrality : the ones that share most similarities with other directors in terms of different collaborations they had throughout their career. Are these only successful directors ? (this is only an idea, maybe the metric to retrieve is not the best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af642971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_degree_centrality(graph):\n",
    "    \"\"\"\n",
    "    Finds the directors with the highest degree centrality : the directors that are the most 'well-connected' to the rest of the network.\n",
    "    \"\"\"\n",
    "    dcs = pd.Series(nx.degree_centrality(graph))\n",
    "    return dcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs = retrieve_degree_centrality(all_bip_proj)\n",
    "dcs = pd.DataFrame({'nm_id': dcs.index, 'degree_centrality': dcs.values})\n",
    "dcs.set_index('nm_id', inplace=True)\n",
    "directors_dc = pd.merge(directors_copy,dcs,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_dc.sort_values(by='degree_centrality',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Q(\"avg-3\") ~ degree_centrality', data=directors_dc).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476e4a8",
   "metadata": {},
   "source": [
    "Nice ! Directors displayed mainly contains directors that are successful to very successful, and the degree centrality is (significantly) correlated with the avg-3 score + R^2 is actually very decent for a single variable. Of course, the metric is not perfect as it can be easily rigged. However, it still shows that there is a singificant impact of the 'network' of relationships for directors : very successful directors definitely tend to 'share' collaborations : famous/successful people work with famous/successful people !\n",
    "\n",
    "\n",
    "--> **Are some directors successful only because they cast popular actors ?** There is a clear relationship, when taking the graphs above, between the successful actors and directors. However, when taking the entirety of the crew jobs at once, we see that it's part of a bigger thing. It's part of the film industry network : successful people tend to work with successful people. Even if there is a clear correlation, the career success is even more linked to the introduction, at some point, of the director into this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d94af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(global_fig, filename=\"interactive_subplot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05706ec",
   "metadata": {},
   "source": [
    "---\n",
    "###  Extra :\n",
    "How are both experience ( i.e how many movies people have directed / worked on etc.) & diversity in their career linked to movie success ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_info = enhanced_directors_df[['primaryName','primaryProfession','avg-3','directed_movies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d79ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_info_filtered = experience_info.copy()\n",
    "experience_info_filtered['num_movies_directed'] = experience_info_filtered['directed_movies'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n",
    "\n",
    "experience_info_filtered['avg-3'] = pd.to_numeric(experience_info['avg-3'], errors='coerce')\n",
    "experience_info_filtered['num_movies_directed'] = pd.to_numeric(experience_info_filtered['num_movies_directed'], errors='coerce')\n",
    "experience_info_filtered = experience_info_filtered.dropna(subset=['avg-3']) ## DROPPING THE NAN AVG-3 VALUE, MODIFY IF SCORE CHANGES\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.regplot(x='num_movies_directed', y='avg-3', data=experience_info_filtered, scatter_kws={'color': PALETTE_D[1]}, line_kws={'color': PALETTE_D[4]})\n",
    "\n",
    "correlation_coefficient = experience_info_filtered['num_movies_directed'].corr(experience_info_filtered['avg-3'])\n",
    "ax.annotate(f'Corr Coef: {correlation_coefficient:.2f}', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', fontsize=10, color='red')\n",
    "plt.title('-')\n",
    "plt.xlabel('Number of Movies Directed')\n",
    "plt.ylabel('avg-3 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_professions = set(','.join(experience_info_filtered['primaryProfession']).split(','))\n",
    "\n",
    "# Create dummy variables for each unique profession\n",
    "for profession in unique_professions:\n",
    "    experience_info_filtered[profession] = experience_info_filtered['primaryProfession'].apply(lambda x: 1 if profession in x else 0)\n",
    "\n",
    "# Filter and calculate mean 'avg-3' for directors who were also actors, producers, etc.\n",
    "mean_avg3_by_profession = {}\n",
    "for profession in unique_professions:\n",
    "        if profession != 'director' :\n",
    "            director_count = experience_info_filtered[experience_info_filtered[profession] == 1].shape[0]\n",
    "            if director_count > 20:\n",
    "                filtered_data = experience_info_filtered[experience_info_filtered[profession] == 1]\n",
    "                mean_avg3_by_profession[profession] = filtered_data['avg-3'].mean()\n",
    "\n",
    "# Sort values based on mean 'avg-3' scores\n",
    "sorted_professions = sorted(mean_avg3_by_profession.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar([item[0] for item in sorted_professions], [item[1] for item in sorted_professions], color=PALETTE_D[1])\n",
    "plt.title('Mean avg-3 Score by Primary Profession')\n",
    "plt.xlabel('Primary Profession')\n",
    "plt.ylabel('Mean avg-3 Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6327e13",
   "metadata": {},
   "source": [
    "### Code for Interactive Plotly graphs displayed on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbeb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as plc\n",
    "\n",
    "def plot_all_directors(start_index):\n",
    "    end_index = start_index + 40\n",
    "    selected_directors = directors_copy.dropna(subset='avg-3').sort_values(by='avg-3', ascending=False).iloc[start_index:end_index]\n",
    "    subgraph = all_bip_proj.subgraph(selected_directors.index.to_list())\n",
    "    edge_weights = nx.get_edge_attributes(subgraph, 'weight')\n",
    "    scaler = MinMaxScaler(feature_range=(0.5, 4))\n",
    "    normalized_weights = scaler.fit_transform([[w] for w in edge_weights.values()])\n",
    "    normalized_weights = {edge: weight[0] for edge, weight in zip(edge_weights.keys(), normalized_weights)}\n",
    "    edge_widths = [normalized_weights[edge] for edge in subgraph.edges]\n",
    "\n",
    "    # Create a Plotly figure\n",
    "    fig = make_subplots()\n",
    "\n",
    "    pos = nx.shell_layout(subgraph)\n",
    "\n",
    "    labels = {node: directors.loc[node, 'primaryName'] for node in subgraph.nodes}\n",
    "    node_colors = directors_copy.loc[list(subgraph.nodes), 'avg-3']\n",
    "    global_min = directors_copy['avg-3'].min()\n",
    "    global_max = directors_copy['avg-3'].max()\n",
    "    norm = Normalize(vmin=global_min, vmax=global_max)\n",
    "    normalized_values = norm(node_colors)\n",
    "    seaborn_colors_rgba = [PALETTE_C(i) for i in range(256)]\n",
    "    seaborn_colors_rgb = [f\"rgb({int(r * 255)}, {int(g * 255)}, {int(b * 255)})\" for (r, g, b, _) in seaborn_colors_rgba]\n",
    "    \n",
    "\n",
    "    #node_colors_mapped = [seaborn_colors_rgba[int(value)] for value in normalized_values]\n",
    "    node_colors_mapped = [seaborn_colors_rgb[int(value * 255)] for value in normalized_values]\n",
    "\n",
    "    edge_traces = []\n",
    "\n",
    "    for edge, width in zip(subgraph.edges(), edge_widths):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_trace = go.Scatter(\n",
    "            x=[x0, x1, None],\n",
    "            y=[y0, y1, None],\n",
    "            line=dict(width=width, color='black'),\n",
    "            hoverinfo='none',\n",
    "            mode='lines'\n",
    "        )\n",
    "        edge_traces.append(edge_trace)\n",
    "    \n",
    "    fig.add_traces(edge_traces)\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    text=[],\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale=seaborn_colors_rgb,\n",
    "        cmin=global_min,\n",
    "        cmax=global_max,\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Director Success Score',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        #line=dict(width=2),\n",
    "        color=node_colors_mapped\n",
    "    ))\n",
    "\n",
    "    for node, color in zip(subgraph.nodes(), node_colors_mapped):\n",
    "        x, y = pos[node]\n",
    "        node_trace['x'] += tuple([x])\n",
    "        node_trace['y'] += tuple([y])\n",
    "        node_trace['text'] += tuple([f'Director: {labels[node]}<br>Score: {directors_copy.loc[node, \"avg-3\"]:.2f}'])\n",
    "        #node_trace['marker']['color'] += tuple([color])\n",
    "\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        height = 650,\n",
    "        width = 750,\n",
    "        margin=dict(b=0, l=0, r=0, t=0),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "\n",
    "    fig.show()\n",
    "    html_file_name = f\"interactive_plot_{start_index}.html\"\n",
    "    fig.write_html(html_file_name)\n",
    "\n",
    "# Use the interact function to connect the sliders to the plot function\n",
    "#interact(plot_all_directors, start_index=start_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_slider = widgets.IntSlider(value=0, min=0, max=len(directors_copy)-40, step=200, description='Start Index:')\n",
    "\n",
    "# Call the plot_all_directors function with the initial value\n",
    "plot_all_directors(start_slider.value)\n",
    "\n",
    "# Define a function to update the plot when the slider value changes\n",
    "def update_plot(change):\n",
    "    plot_all_directors(change.new)\n",
    "\n",
    "# Connect the update_plot function to the slider's value change event\n",
    "start_slider.observe(update_plot, 'value')\n",
    "\n",
    "# Display the slider\n",
    "display(start_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c201fd",
   "metadata": {},
   "source": [
    "# Q2: To what extent does the director’s choice of movie genre affect the success of the movie?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b54d1",
   "metadata": {},
   "source": [
    "# Q3: What is the impact of the director’s character choices on the success of the movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95999b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import entropy\n",
    "import copy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers.readers import read_dataframe\n",
    "DATA_PATH = './generated/annotations_2023/'\n",
    "DATA_PATH_GENERATED = './generated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f133a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_movie_directors_ori=pd.read_parquet(os.path.join(DATA_PATH, \"character_movie_directors.parquet\"), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_movie_directors_ori.head()\n",
    "print('There are {} chractors with chractor types in the dataset'.format(len(character_movie_directors_ori)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bde3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(character_movie_directors_ori.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_movies = read_dataframe(\n",
    "    name='cmu/movies',\n",
    "    preprocess=True,\n",
    "    usecols=[\n",
    "        \"Wikipedia movie ID\",\n",
    "        \"Freebase movie ID\",\n",
    "        \"Movie name\",\n",
    "        \"Movie release date\",\n",
    "        \"Movie box office revenue\",\n",
    "        \"Movie runtime\",\n",
    "        \"Movie languages\",\n",
    "        \"Movie countries\",\n",
    "        \"Movie genres\",\n",
    "    ]\n",
    ")\n",
    "mapping_f_i = read_dataframe(name='mapping_freebase_imdb')\n",
    "imdb_ratings = read_dataframe(name='imdb/ratings')\n",
    "imdb_crew = read_dataframe(name='imdb/crew')\n",
    "imdb_people = read_dataframe(name='imdb/names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = cmu_movies.drop(['Movie release Day', 'Movie release Month'], axis=1).copy()\n",
    "movies.rename(\n",
    "    columns={\n",
    "        'Wikipedia movie ID': 'wikipediaID',\n",
    "        'Freebase movie ID': 'freebaseID',\n",
    "        'Movie name': 'title',\n",
    "        'Movie box office revenue': 'revenue',\n",
    "        'Movie runtime': 'runtime',\n",
    "        'Movie languages': 'languages',\n",
    "        'Movie countries': 'countries',\n",
    "        'Movie genres': 'genres',\n",
    "        'Movie release Year': 'release',\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "movies = movies.merge(\n",
    "    right=mapping_f_i.drop_duplicates(subset='freebase'),\n",
    "    left_on='freebaseID', right_on='freebase', how='left'\n",
    ").rename(columns={'imdb': 'tconst'}).drop('freebase', axis=1)\n",
    "movies.tconst.duplicated().sum()\n",
    "movies.drop_duplicates(subset='tconst', inplace=True)\n",
    "movies = movies.merge(\n",
    "    right=imdb_ratings.rename(columns={'averageRating': 'rating', 'numVotes': 'votes'}),\n",
    "    on='tconst', how='left',\n",
    ")\n",
    "movies = movies.merge(right=imdb_crew.drop('writers', axis=1), on='tconst', how='left')\n",
    "movies = movies.set_index('tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293417eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmconsts = []\n",
    "for item in movies.dropna(subset='directors').directors.str.split(','):\n",
    "    nmconsts.extend(item)\n",
    "nmconsts = set(nmconsts)\n",
    "\n",
    "directors = imdb_people[imdb_people.nconst.isin(nmconsts)].copy()\n",
    "directors = directors.set_index('nconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65488a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install memory_profiler\n",
    "# install and load memory_profiler to use %memit, use %whos to see what's in memory\n",
    "%reload_ext memory_profiler\n",
    "%memit\n",
    "import gc\n",
    "\n",
    "del imdb_people\n",
    "del mapping_f_i\n",
    "del cmu_movies\n",
    "del imdb_ratings\n",
    "del imdb_crew\n",
    "\n",
    "gc.collect()\n",
    "%memit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c83ce",
   "metadata": {},
   "source": [
    "## 3.1 What types of characters do successful directors choose ? \n",
    "\n",
    "First, we need to establish a metric to measure movie sucess, and based one it we can assess director success. Drawing upon past exploration and the definition of director success, we can generate the following dataframe containing success scores for directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to calculate the score of a movie\n",
    "def metric(row):\n",
    "    return np.log10(row['votes']) * row['rating']\n",
    "\n",
    "movies['score'] = movies.apply(metric, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90030db",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_parquet(os.path.join(DATA_PATH_GENERATED, \"movie_with_score.parquet\"), compression= \"brotli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d1709",
   "metadata": {},
   "source": [
    "# FLAG\n",
    "**Load directors with scores (q1 directors)**\n",
    "# FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_with_score=copy.deepcopy(directors)\n",
    "# Get the directors information for the directors who has chracter type information\n",
    "directors_with_score=pd.merge(character_movie_directors_ori, directors_with_score, left_on='directors', right_on='nconst', how='left')\n",
    "directors_with_score=directors_with_score.drop(['primaryProfession', 'knownForTitles','Wikipedia movie ID', 'Freebase movie ID', 'Movie name',\n",
    "       'Character name', 'tconst', 'freebase', 'imdb', 'movieid_charactername', 'topic', 'topic_dist'], axis=1)\n",
    "directors_with_score=directors_with_score.drop_duplicates(subset=['directors']).reset_index(drop=True)\n",
    "display(directors_with_score.head())\n",
    "print('There are {} directors in the dataset'.format(len(directors_with_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efc7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_movie_directors=copy.deepcopy(character_movie_directors_ori)\n",
    "# Add primaryName to character_movie_directors\n",
    "character_movie_directors = character_movie_directors.merge(directors_with_score[['directors', 'primaryName']], left_on='directors', right_on='directors', how='left')\n",
    "character_movie_directors=character_movie_directors.drop(['imdb','freebase'],axis=1)\n",
    "display(character_movie_directors.head())\n",
    "print('There are {} chractors with chractor types in the dataset'.format(len(character_movie_directors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_with_score.sort_values(by='avg-3', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13032f",
   "metadata": {},
   "source": [
    "Let's have a look of the score distribution of directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_with_score['avg-3'].plot.hist(bins=20)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of directors')\n",
    "plt.title('Distribution of score for directors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39752c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chractor_with_director_with_score=pd.merge(character_movie_directors, directors_with_score, left_on=['directors','primaryName'], right_on=['directors','primaryName'], how='left')\n",
    "chractor_with_director_with_score=chractor_with_director_with_score[['directors','primaryName','avg-3','avg-5','Movie name','Character name','movieid_charactername','topic']]\n",
    "display(chractor_with_director_with_score.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c02207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value for score, on column avg-3\n",
    "print('There are {} missing value when using score avg-3'.format(directors_with_score['avg-3'].isnull().sum()))\n",
    "print('There are {} missing value when using score avg-5'.format(directors_with_score['avg-5'].isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e0468",
   "metadata": {},
   "source": [
    "In the earlier examination of director success scores, it was noted that both avg-3 and avg-5 exhibit robustness. Since avg-3 has fewer missing values, it will be employed as the score for assessing the success of directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with director name, score, a list of 'Character name', and corresponding chractor topics to show the chractor choice of success directors\n",
    "chractor_director_score=chractor_with_director_with_score.groupby(['directors','primaryName','avg-3'])[['Character name','topic']].agg(lambda x: list(x)).reset_index()\n",
    "chractor_director_score=chractor_director_score.sort_values(by='avg-3', ascending=False).reset_index(drop=True)\n",
    "display(chractor_director_score.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_topic=chractor_director_score[['primaryName','topic']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca283c",
   "metadata": {},
   "source": [
    "Before checking out successful directors, let's first see the distribution of character types chosen by all directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a43fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most frequenct n topics of top n directors\n",
    "def get_topn_topic(n_director=10, n_topic=50):\n",
    "    if n_director>len(director_topic):\n",
    "        print('The number of directors is less than the number of directors you want to get, please input a smaller number')\n",
    "        return\n",
    "    elif n_director==0:\n",
    "        n_director=len(director_topic)\n",
    "    topic_list=[]\n",
    "    for i in range(n_director):\n",
    "        topic_list.extend(director_topic['topic'][i])\n",
    "    topic_list=pd.Series(topic_list)\n",
    "    topn_topic=topic_list.value_counts()[:n_topic].index.tolist()\n",
    "    topic_dist=topic_list.value_counts()[:n_topic].values.tolist()\n",
    "    return topn_topic, topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topic distribution for all directors\n",
    "topn_topicn,topic_dist=get_topn_topic(n_director=0, n_topic=50)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(topn_topicn, topic_dist)\n",
    "plt.xlabel('Charcter type')\n",
    "plt.ylabel('Number of directors')\n",
    "plt.title('Charcter type distribution of the top 10 directors')\n",
    "plt.xticks(topn_topicn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88474270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topn_directors_topics(n=10):\n",
    "    for i in range(n):\n",
    "        print('{}: {}'.format(director_topic['primaryName'][i], sorted(set(pd.Series(director_topic['topic'][i]).unique()))))\n",
    "print('Top 10 directors and their choice of chracters:')\n",
    "print_topn_directors_topics(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a79802",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_topic_top10=director_topic[:10]\n",
    "matrix = np.zeros((10, 50))\n",
    "directors_name=director_topic_top10['primaryName'].tolist()\n",
    "\n",
    "for i, row in director_topic_top10.iterrows():\n",
    "    for character in row['topic']:\n",
    "        matrix[i, character] +=1\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(matrix, cmap='viridis', cbar_kws={'label': 'Chosen times'})\n",
    "plt.xlabel('Chracter type')\n",
    "plt.ylabel('Director')\n",
    "plt.yticks(np.arange(0.5, 10.5), directors_name, rotation=0)\n",
    "plt.title('Director Character Choices Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162bd03",
   "metadata": {},
   "source": [
    "We can observe that most of top10 directors they worked with various types of chractors. Let's have a closer look with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ddb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data frame for the top 10 words of topics of the LDA model we used for chractor type annotation\n",
    "lda_topic_words = pd.read_csv(os.path.join(DATA_PATH_GENERATED, 'annotations_2023/topic_top_words.txt'), sep=\":\", header=None, names=['topic', 'top_words'])\n",
    "lda_topic_words['topic']=lda_topic_words['topic'].str.replace('Topic ', '')\n",
    "# display(lda_topic_words.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_topicn,_=get_topn_topic(n_director=10, n_topic=5)\n",
    "print('The top 5 topics of the top 10 directors are: {}\\n'.format(topn_topicn))\n",
    "print('Following are the top 10 wrods of each topic:')\n",
    "for i in topn_topicn:\n",
    "    print('Topic {}: {}'.format(i, lda_topic_words[lda_topic_words['topic']==str(i)]['top_words'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad110b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topic distribution of the top 10 directors\n",
    "topn_topicn,topic_dist=get_topn_topic(n_director=10, n_topic=50)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(topn_topicn, topic_dist)\n",
    "plt.xlabel('Chracter type')\n",
    "plt.ylabel('Number of directors')\n",
    "plt.title('Chracter type distribution of the top 10 directors')\n",
    "plt.xticks(topn_topicn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef1b5c",
   "metadata": {},
   "source": [
    "## 3.2 How diverse the directors are in their character choices ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by directors\n",
    "directors_group = character_movie_directors.groupby('directors').agg({'Wikipedia movie ID': lambda x: list(x), 'Freebase movie ID': lambda x: list(x), 'Movie name': lambda x: list(x), 'Character name': lambda x: list(x), 'topic': lambda x: list(x), 'tconst': lambda x: list(x),'primaryName':lambda x: list(x)})\n",
    "# character_movie_directors_group.head(3)\n",
    "print('There are {} unique directors who has the chracter type information'.format(directors_group.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique characters for each director\n",
    "unique_characters = character_movie_directors.groupby('directors')['topic'].nunique()\n",
    "\n",
    "# Count the number of directors for each unique number of characters\n",
    "directors_by_unique_count = unique_characters.value_counts()\n",
    "\n",
    "# Group together directors with more than 10 unique characters\n",
    "threshold = 10\n",
    "large_counts = directors_by_unique_count[directors_by_unique_count.index >= threshold]\n",
    "directors_by_unique_count = directors_by_unique_count.drop(large_counts.index)\n",
    "directors_by_unique_count[f'>= {threshold}'] = large_counts.sum()\n",
    "\n",
    "# Create a pie chart to show the distribution with a custom color map\n",
    "labels = directors_by_unique_count.index.astype(str)\n",
    "sizes = directors_by_unique_count.values\n",
    "colors = plt.cm.tab10(range(len(labels)))\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Directors by Number of Unique Characters he/she worked with')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9aa7c",
   "metadata": {},
   "source": [
    "Let's have a close look of ten directors with the highest diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f927678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique characters for each director\n",
    "unique_characters = character_movie_directors.groupby('directors')['topic'].nunique()\n",
    "\n",
    "# Map director IDs to corresponding 'primaryName'\n",
    "directors_mapping = character_movie_directors.set_index('directors')['primaryName'].to_dict()\n",
    "unique_characters.index = unique_characters.index.map(directors_mapping)\n",
    "\n",
    "# Sort directors based on diversity\n",
    "sorted_directors = unique_characters.sort_values()\n",
    "\n",
    "# Visualize the ten directors with the highest diversity\n",
    "plt.figure(figsize=(12, 6))\n",
    "sorted_directors.tail(10).plot(kind='barh', color='skyblue')\n",
    "plt.title('Top 10 Directors with Highest Diversity')\n",
    "plt.xlabel('Number of Unique Characters')\n",
    "plt.ylabel('Director')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35243100",
   "metadata": {},
   "source": [
    "From the above pie chart, we can observe that almost half of the directors only worked with one or two chractor type. However, using this method to define the diversity of directors' chatacter choices  might be subject to the influence of the total number of movies each director has undertaken. To achieve a more precise quantification of the diversity in directors' character choices, we need a more refined quantitative method.\n",
    "\n",
    "#### Quantify diversity\n",
    "For quantify diversity, we calculate the Shannon diversity index with normalization for each director based on the distribution of chracter types in their movies. Higher entropy values indicate grater diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92327955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Shannon Diversity Index with normalization by the number of chractors\n",
    "director_diversity = character_movie_directors.groupby('directors')['topic'].apply(lambda x: entropy(pd.Series(x).value_counts() / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ten directors with the highest diversity\n",
    "\n",
    "# Map director IDs to corresponding 'primaryName'\n",
    "director_diversity_map=copy.deepcopy(director_diversity)\n",
    "director_diversity_map.index = director_diversity_map.index.map(directors_mapping)\n",
    "\n",
    "# Sort directors based on diversity\n",
    "sorted_director_diversity = director_diversity_map.sort_values()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sorted_director_diversity.tail(10).plot(kind='barh', color='skyblue')\n",
    "plt.title('Top 10 Directors with Highest Diversity Score')\n",
    "plt.xlabel('Diversity score')\n",
    "plt.ylabel('Director')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff436cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_category={'0': 'tab:orange', '0.00-1.00': 'tab:green', '1.00-2.00': 'tab:blue', '2.00-3.00': 'tab:red', '3.00-4.00': 'tab:purple'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart to show the distribution of diversity scores\n",
    "\n",
    "# Define bins for categorizing diversity scores\n",
    "bins = [-1e-10, 1e-10, 1, 2, 3, 4] \n",
    "\n",
    "# Categorize directors based on diversity scores\n",
    "diversity_categories = pd.cut(sorted_director_diversity, bins=bins, include_lowest=True)\n",
    "\n",
    "# Calculate the percentage of directors in each category\n",
    "percentage_by_category = diversity_categories.value_counts(normalize=False) * 100\n",
    "\n",
    "labels = [f'{category.left:.2f}-{category.right:.2f}' if category.left > 0 else '0' for category in percentage_by_category.index]\n",
    "sizes = percentage_by_category.values\n",
    "# Assigning colors based on categories\n",
    "colors = [color_category[label] for label in labels]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Directors by calculating Shannon diversity index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c4977",
   "metadata": {},
   "source": [
    "Based on the information presented in the pie chart, it is evident that 32.6% of directors exhibit a diversity score falling within the 1-2 range. Additionally, 31.6% of directors possess a diversity score of 0, indicating that their works predominantly feature a single character type. It's worth noting that this might be influenced by the limitations of the plot data available from CMU, as not all movies and characters have sufficient information to determine character types accurately. In the 0-1 range, 20.1% of directors fall into this category, while 13.8% fall within the 2-3 range. Notably, only 1.9% of directors attain a score of 3-4, indicating a higher diversity of character types in their works.\n",
    "\n",
    "## 3.3 Can we find very successful directors that always use the same type of characters or others that vary a lot in their personas choices ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_with_diversescore=pd.merge(pd.DataFrame(director_diversity.reset_index()), directors_with_score, how='left', left_on='directors', right_on='directors')\n",
    "director_with_diversescore.rename(columns={'topic':'diversity_score'}, inplace=True)\n",
    "director_with_diversescore.sort_values(by='avg-3', ascending=False, inplace=True)\n",
    "display(director_with_diversescore.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ea0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topn_directors_diversityscore(n=10):\n",
    "    return director_with_diversescore[:n].sort_values(by='avg-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the top ten most \"success\" directors with their diversity score\n",
    "plt.figure(figsize=(12, 6))\n",
    "director_with_diversescore_10=get_topn_directors_diversityscore(n=10)\n",
    "director_with_diversescore_10.tail(10).plot(kind='barh', x='primaryName', y='diversity_score', color='skyblue', legend=False)\n",
    "plt.title('Top 10 sucess Directors with Diversity Score')\n",
    "plt.xlabel('Diversity score')\n",
    "plt.ylabel('Director')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dfecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize directors based on diversity scores\n",
    "bins = [-1e-10, 1e-10, 1, 2, 3, 4] \n",
    "success_diversity_categories = pd.cut(director_diversity, bins=bins, include_lowest=True)\n",
    "\n",
    "# Create a pie chart to show the distribution of diversity scores of top 10 success directors\n",
    "percentage_by_category_10 = success_diversity_categories[director_with_diversescore_10.directors].value_counts(normalize=False) * 100\n",
    "percentage_by_category_10=percentage_by_category_10[percentage_by_category_10!=0]\n",
    "labels = [f'{category.left:.2f}-{category.right:.2f}' if category.left > 0 else '0' for category in percentage_by_category_10.index]\n",
    "sizes = percentage_by_category_10.values\n",
    "# Assigning colors based on categories\n",
    "colors = [color_category[label] for label in labels]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of diversity scores of top 10 success directors')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395061e2",
   "metadata": {},
   "source": [
    "Most successful directors seem to have a diversity score falling between 3 and 4, indicating a high diversity of personas in their movies. Let's explore this further by examining the top 20 successful directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0937205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart to show the distribution of diversity scores of top 20 success directors\n",
    "director_with_diversescore_20=get_topn_directors_diversityscore(n=20)\n",
    "percentage_by_category_20 = success_diversity_categories[director_with_diversescore_20.directors].value_counts(normalize=False) * 100\n",
    "percentage_by_category_20=percentage_by_category_20[percentage_by_category_20!=0]\n",
    "labels = [f'{category.left:.2f}-{category.right:.2f}' if category.left > 0 else '0' for category in percentage_by_category_20.index]\n",
    "sizes = percentage_by_category_20.values\n",
    "# Assigning colors based on categories\n",
    "colors = [color_category[label] for label in labels]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of diversity scores of top 20 success directors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4aa01",
   "metadata": {},
   "source": [
    "We can observe that the distribution of lower diversity score boecome larger. Let's see more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703000d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(1,17):\n",
    "    number=i*100\n",
    "    director_with_diversescore_n=get_topn_directors_diversityscore(n=number)\n",
    "    percentage_by_category_n = success_diversity_categories[director_with_diversescore_n.directors].value_counts(normalize=False) * 100\n",
    "    percentage_by_category_n=percentage_by_category_n[percentage_by_category_n!=0]\n",
    "    labels = [f'{category.left:.2f}-{category.right:.2f}' if category.left > 0 else '0' for category in percentage_by_category_n.index]\n",
    "    sizes = percentage_by_category_n.values\n",
    "    # Assigning colors based on categories\n",
    "    colors = [color_category[label] for label in labels]\n",
    "\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title('Top {} success directors'.format(number))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7d23a",
   "metadata": {},
   "source": [
    "Here, we notice that as more top successful directors are included, the distribution of high diversity scores decreases. This prompts the question: is there a correlation between the diversity of character types and the success of directors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns\n",
    "director_with_diversescore.rename(columns={'avg-3':'director_score'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares a linear regression model\n",
    "model = smf.ols(formula='director_score ~ diversity_score', data=director_with_diversescore).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba508e1",
   "metadata": {},
   "source": [
    "Let's examine some key findings derived from the analysis. Firstly, the coefficient for diversity_score is 5.3351, indicating that with each unit increase in the diversity score, we anticipate an approximate 5.33-point rise in the director score. Essentially, this implies a positive correlation between the director score and the diversity score. Secondly, the p-value associated with the coefficient is <0.05. This indicates that, within the framework of this model, the coefficients are statistically significant, signifying that the diversity score is indeed valuable in predicting the director score.\n",
    "\n",
    "## 3.4 In definitive, how does this impact the movie’s success ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb15dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_parquet(os.path.join(DATA_PATH_GENERATED, \"movie_with_score.parquet\"), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed63f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_socres=copy.deepcopy(movies)\n",
    "movies_with_socres=movies_with_socres.reset_index().drop(['revenue','rating','votes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7002d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chractor_movie_with_score=pd.merge(character_movie_directors, movies_with_socres, left_on='tconst', right_on='tconst', how='left')\n",
    "chractor_movie_with_score=chractor_movie_with_score.drop(['Wikipedia movie ID', 'Freebase movie ID', 'Movie name',\n",
    "     'freebaseID', 'wikipediaID','directors_y','wikipediaID','freebaseID'], axis=1)\n",
    "#rename directors_x to directors\n",
    "chractor_movie_with_score.rename(columns={'directors_x':'directors', 'primaryName':'directors_name','Character name':'character_name'}, inplace=True)\n",
    "chractor_movie_director_with_score=pd.merge(chractor_movie_with_score, director_with_diversescore, left_on='directors', right_on='directors', how='left')\n",
    "chractor_movie_director_with_score.drop(['primaryName','hits-30', 'hits-40', 'hits-45', 'hits-50',\n",
    "       'rate-7.0', 'rate-7.5', 'rate-8.0', 'rate-8.5','avg-5','avg-10'], axis=1, inplace=True)\n",
    "display(chractor_movie_director_with_score.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average movie score of each chractor type\n",
    "plt.figure(figsize=(15,5))\n",
    "chractor_movie_director_with_score.groupby('topic')['score'].mean().plot.bar()\n",
    "plt.xlabel('Chracter type')\n",
    "plt.ylabel('Average movie score')\n",
    "plt.title('Average movie score of each chracter type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe2839",
   "metadata": {},
   "source": [
    "In the above plot, we can see that the scores for different types of characters are quite similar. Therefore, there isn't a specific character type with a significantly higher movie score. However, let's delve deeper to investigate whether there is a relationship between the movie score and the character type for each directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a512d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dirtribution of movie score and chractor type for each director\n",
    "director_topic_score=chractor_movie_director_with_score.groupby(['directors','topic'])['score'].mean().reset_index()\n",
    "director_topic_score=director_topic_score.pivot(index='directors', columns='topic', values='score')\n",
    "director_topic_score=director_topic_score.reset_index()\n",
    "director_topic_score=director_topic_score.merge(director_with_diversescore[['directors','director_score']], left_on='directors', right_on='directors', how='left')\n",
    "director_topic_score=director_topic_score.dropna(subset=['director_score'])\n",
    "director_topic_score=director_topic_score.set_index('directors')\n",
    "director_topic_score=director_topic_score.sort_values(by='director_score', ascending=False)\n",
    "director_topic_score=director_topic_score.drop('director_score', axis=1)\n",
    "director_topic_score=director_topic_score.reset_index()\n",
    "\n",
    "# The distribution of movie score and chractor type for top 9 success directors\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(0,9):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    director_topic_score.iloc[i,1:].plot.bar(stacked=True)\n",
    "    plt.xlabel('chrater type')\n",
    "    plt.ylabel('Movie score')\n",
    "    plt.title('Distribution of movie score and chracter type for {}'.format(directors_mapping[director_topic_score.iloc[i,0]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5db98",
   "metadata": {},
   "source": [
    "Returning to the earlier question: does the diversity of character types among a director's works impact the director's success or the success of their movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chractor_movie_diversity=chractor_movie_director_with_score.drop_duplicates(subset=['tconst']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declares a linear regression model\n",
    "model = smf.ols(formula='score ~ diversity_score', data=chractor_movie_diversity).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec24b4",
   "metadata": {},
   "source": [
    "Let's examine some key findings derived from the analysis. Firstly, the coefficient for diversity_score is 3.7065, indicating that with each unit increase in the diversity score, we anticipate an approximate 3.7-point rise in the movie score. Essentially, this implies a positive correlation between the movie score and the diversity score. Secondly, the p-value associated with the coefficient is <0.05. This indicates that, within the framework of this model, the coefficients are statistically significant, signifying that the diversity score is indeed valuable in predicting the movie score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e128d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score=chractor_movie_diversity['score'].mean()\n",
    "max_score=chractor_movie_diversity['score'].max()\n",
    "print('The average score of all movies is {}'.format(avg_score))\n",
    "print('The max score of all movies is {}'.format(max_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d3ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A box plot to show the distribution of movie score\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.boxplot(x=chractor_movie_diversity['score'])\n",
    "plt.xlabel('Movie score')\n",
    "plt.title('Distribution of movie score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19225a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "chractor_movie_diversity_sucess=copy.deepcopy(chractor_movie_diversity)\n",
    "chractor_movie_diversity_sucess['movie_sucess']=chractor_movie_diversity_sucess['score'].apply(lambda x: 1 if x>23 else 0)\n",
    "# print(chractor_movie_diversity_sucess.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_df = chractor_movie_diversity_sucess[chractor_movie_diversity_sucess['movie_sucess'] == True]\n",
    "control_df = chractor_movie_diversity_sucess[chractor_movie_diversity_sucess['movie_sucess'] == False]\n",
    "print(len(treatment_df), 'movies in our dataset that considered as sucessed (treatment group).')\n",
    "print(len(control_df), 'papers in our dataset that considered as sucessed (control group).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95042253",
   "metadata": {},
   "outputs": [],
   "source": [
    "chractor_movie_diversity_sucess.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac562340",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for languages in tqdm(chractor_movie_diversity_sucess['languages'].unique()):\n",
    "    treat_lan_df = treatment_df[treatment_df['languages'] == languages]\n",
    "    control_lan_df = control_df[control_df['languages'] == languages]\n",
    "    for countries in treat_lan_df['countries'].unique():\n",
    "        treat_con_df = treat_lan_df[treat_lan_df['countries'] == countries]\n",
    "        control_con_df = control_lan_df[control_lan_df['countries'] == countries]\n",
    "        # for genres in treat_con_df['genres'].unique():\n",
    "        #     genres=genres.split(',')\n",
    "        #     treat_gen_df = treat_con_df[treat_con_df['genres'].apply(lambda x: set(x.split(','))).apply(lambda x: bool(x.intersection(set(genres))))]\n",
    "        #     control_gen_df = control_con_df[control_con_df['genres'].apply(lambda x: set(x.split(','))).apply(lambda x: bool(x.intersection(set(genres))))]\n",
    "        for control_id, control_row in control_con_df.iterrows():\n",
    "            for treatment_id, treatment_row in treat_con_df.iterrows():\n",
    "                # Match papers with exactly the same overall score before rebuttal\n",
    "                if control_row[\"director_score\"] == treatment_row[\"director_score\"]:\n",
    "                    G.add_edge(control_id, treatment_id)\n",
    "\n",
    "matching = nx.maximal_matching(G) # ensure one match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = chractor_movie_diversity_sucess.copy()\n",
    "matched_df['matched_id'] = np.nan\n",
    "\n",
    "for i, (treatment_index, control_index) in enumerate(matching):\n",
    "    matched_df.loc[treatment_index, 'matched_id'] = i\n",
    "    matched_df.loc[control_index, 'matched_id'] = i\n",
    "\n",
    "matched_df = matched_df.dropna(subset=['matched_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(matched_df.sort_values(by='matched_id').head(10))\n",
    "sucess_counts = matched_df['movie_sucess'].value_counts()\n",
    "\n",
    "print('We have', len(matched_df),'in the resulting dataframe')\n",
    "print(f\"Number of movies are considered as success: {sucess_counts[1]}\")\n",
    "print(f\"Number of movies are considered as success: {sucess_counts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_model = smf.ols(formula='score ~ diversity_score', data=matched_df).fit()\n",
    "\n",
    "print(matched_model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
